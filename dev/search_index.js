var documenterSearchIndex = {"docs":
[{"location":"tutorial-discretisation.html#tutorial-discretisation-methods","page":"Discretisation methods","title":"Discretisation methods","text":"","category":"section"},{"location":"tutorial-discretisation.html","page":"Discretisation methods","title":"Discretisation methods","text":"In this tutorial, we will explore the different discretisation methods available in the OptimalControl.jl package. These methods are used to convert a continuous-time optimal control problem (OCP) into a discrete-time nonlinear programming (NLP) problem, which can then be solved using numerical optimization techniques.","category":"page"},{"location":"tutorial-discretisation.html","page":"Discretisation methods","title":"Discretisation methods","text":"Let us import the necessary packages and define the optimal control problem (Goddard problem) we will use as an example throughout this tutorial.","category":"page"},{"location":"tutorial-discretisation.html","page":"Discretisation methods","title":"Discretisation methods","text":"using BenchmarkTools  # for benchmarking\nusing DataFrames      # to store the results\nusing OptimalControl  # to define the optimal control problem and more\nusing NLPModels       # to retrieve information about the NLP problem \nusing NLPModelsIpopt  # to solve the problem via a direct method\nusing Plots           # to plot the solution\n\nconst t0 = 0      # initial time\nconst r0 = 1      # initial altitude\nconst v0 = 0      # initial speed\nconst m0 = 1      # initial mass\nconst vmax = 0.1  # maximal authorized speed\nconst mf = 0.6    # final mass to target\n\nocp = @def begin # definition of the optimal control problem\n\n    tf ∈ R, variable\n    t ∈ [t0, tf], time\n    x = (r, v, m) ∈ R³, state\n    u ∈ R, control\n\n    x(t0) == [r0, v0, m0]\n    m(tf) == mf\n    0 ≤ u(t) ≤ 1\n    r(t) ≥ r0\n    0 ≤ v(t) ≤ vmax\n\n    ẋ(t) == F0(x(t)) + u(t) * F1(x(t))\n\n    r(tf) → max\n\nend;\n\n# Dynamics\nconst Cd = 310\nconst Tmax = 3.5\nconst β = 500\nconst b = 2\n\nF0(x) = begin\n    r, v, m = x\n    D = Cd * v^2 * exp(-β*(r - 1)) # Drag force\n    return [ v, -D/m - 1/r^2, 0 ]\nend\n\nF1(x) = begin\n    r, v, m = x\n    return [ 0, Tmax/m, -b*Tmax ]\nend\nnothing # hide","category":"page"},{"location":"tutorial-discretisation.html#Discretisation-schemes","page":"Discretisation methods","title":"Discretisation schemes","text":"","category":"section"},{"location":"tutorial-discretisation.html","page":"Discretisation methods","title":"Discretisation methods","text":"When calling solve, the option disc_method=... can be used to specify the discretization scheme. In addition to the default implicit :trapeze method (also known as Crank–Nicolson), other available options include the implicit :midpoint method, and Gauss–Legendre collocation schemes with 2 and 3 stages: :gauss_legendre_2 and :gauss_legendre_3, of order 4 and 6 respectively. Note that higher-order methods typically result in larger NLP problems for the same number of time steps, and their accuracy also depends on the smoothness of the problem.","category":"page"},{"location":"tutorial-discretisation.html","page":"Discretisation methods","title":"Discretisation methods","text":"Let us first solve the problem with the default :trapeze method and display the solution.","category":"page"},{"location":"tutorial-discretisation.html","page":"Discretisation methods","title":"Discretisation methods","text":"sol = solve(ocp; disc_method=:trapeze, display=false)\nplot(sol; size=(800, 800))","category":"page"},{"location":"tutorial-discretisation.html","page":"Discretisation methods","title":"Discretisation methods","text":"Let us now compare different discretization schemes to evaluate their accuracy and performance.","category":"page"},{"location":"tutorial-discretisation.html","page":"Discretisation methods","title":"Discretisation methods","text":"# Solve the problem with different discretization methods\nsolutions = []\ndata = DataFrame(\n    Scheme=Symbol[],\n    Time=Float64[],\n    Objective=Float64[], \n    Iterations=Int[]\n)\nschemes = [\n    :euler, \n    :euler_implicit,\n    :trapeze, \n    :midpoint, \n    :gauss_legendre_2, \n    :gauss_legendre_3\n]\nfor scheme in schemes\n    bt = @btimed solve($ocp; disc_method=$scheme, tol=1e-8, display=false)\n    local sol = bt.value\n    push!(solutions, (scheme, sol))\n    push!(data, (\n        Scheme=scheme, \n        Time=bt.time, \n        Objective=objective(sol), \n        Iterations=iterations(sol)\n    ))\nend\nprintln(data)","category":"page"},{"location":"tutorial-discretisation.html","page":"Discretisation methods","title":"Discretisation methods","text":"# Plot the results\nx_style = (legend=:none,)\np_style = (legend=:none,)\nstyles = (state_style=x_style, costate_style=p_style)\n\nscheme, sol = solutions[1]\nplt = plot(sol; label=string(scheme), styles...)\nfor (scheme, sol) in solutions[2:end]\n    plt = plot!(sol; label=string(scheme), styles...)\nend\nplot(plt; size=(800, 800))","category":"page"},{"location":"tutorial-discretisation.html#Large-problems-and-AD-backend","page":"Discretisation methods","title":"Large problems and AD backend","text":"","category":"section"},{"location":"tutorial-discretisation.html","page":"Discretisation methods","title":"Discretisation methods","text":"For some large problems, you may notice that the solver takes a long time before the iterations actually begin. This is due to the computation of sparse derivatives — specifically, the Jacobian of the constraints and the Hessian of the Lagrangian — which can be quite costly. One possible alternative is to set the option adnlp_backend=:manual, which uses simpler sparsity patterns. The resulting matrices are faster to compute but are also less sparse, so this represents a trade-off between automatic differentiation (AD) preparation time and the efficiency of the optimization itself.","category":"page"},{"location":"tutorial-discretisation.html","page":"Discretisation methods","title":"Discretisation methods","text":"solve(ocp; disc_method=:gauss_legendre_3, grid_size=1000, adnlp_backend=:manual)\nnothing # hide","category":"page"},{"location":"tutorial-discretisation.html","page":"Discretisation methods","title":"Discretisation methods","text":"Let us now compare the performance of the two backends. We will use the @btimed macro from the BenchmarkTools package to measure the time taken for both the preparation of the NLP problem and the execution of the solver. Besides, we will also collect the number of non-zero elements in the Jacobian and Hessian matrices, which can be useful to understand the sparsity of the problem, thanks to the functions get_nnzo, get_nnzj, and get_nnzj from the NLPModels package. The problem is first discretized with the direct_transcription method and then solved with the ipopt solver, see the tutorial on direct transcription for more details.","category":"page"},{"location":"tutorial-discretisation.html","page":"Discretisation methods","title":"Discretisation methods","text":"# DataFrame to store the results\ndata = DataFrame(\n    Backend=Symbol[],\n    NNZO=Int[],\n    NNZJ=Int[],\n    NNZH=Int[],\n    PrepTime=Float64[],\n    ExecTime=Float64[],\n    Objective=Float64[], \n    Iterations=Int[]\n)\n\n# The different AD backends to test\nbackends = [:optimized, :manual]\n\n# Loop over the backends\nfor adnlp_backend in backends\n\n    # Discretize the problem with a large grid size and Gauss-Legendre method\n    bt = @btimed direct_transcription($ocp; \n        disc_method=:gauss_legendre_3, \n        grid_size=1000, \n        adnlp_backend=$adnlp_backend,\n    )\n    docp, nlp = bt.value\n    prepa_time = bt.time\n\n    # Get the number of non-zero elements\n    nnzo = get_nnzo(nlp) # Gradient of the Objective\n    nnzj = get_nnzj(nlp) # Jacobian of the constraints\n    nnzh = get_nnzh(nlp) # Hessian of the Lagrangian\n\n    # Solve the problem\n    bt = @btimed ipopt($nlp; \n        print_level=0, \n        mu_strategy=\"adaptive\", \n        tol=1e-8,\n        sb=\"yes\",\n    )\n    nlp_sol = bt.value\n    exec_time = bt.time\n\n    # Store the results in the DataFrame\n    push!(data, \n        (\n            Backend=adnlp_backend, \n            NNZO=nnzo, \n            NNZJ=nnzj, \n            NNZH=nnzh, \n            PrepTime=prepa_time, \n            ExecTime=exec_time, \n            Objective=-nlp_sol.objective, \n            Iterations=nlp_sol.iter\n        )\n    )\nend\nprintln(data)","category":"page"},{"location":"tutorial-discretisation.html#Explicit-time-grid","page":"Discretisation methods","title":"Explicit time grid","text":"","category":"section"},{"location":"tutorial-discretisation.html","page":"Discretisation methods","title":"Discretisation methods","text":"The option time_grid=... allows you to provide the full time grid vector t0, t1, ..., tf, which is especially useful if a non-uniform grid is desired. In the case of a free initial and/or final time, you should provide a normalized grid ranging from 0 to 1. Note that time_grid overrides grid_size if both options are specified.","category":"page"},{"location":"tutorial-discretisation.html","page":"Discretisation methods","title":"Discretisation methods","text":"sol = solve(ocp; time_grid=[0, 0.1, 0.5, 0.9, 1], display=false)\nprintln(time_grid(sol))","category":"page"},{"location":"tutorial-mam.html#Minimal-Action-Method-using-Optimal-Control","page":"Minimal action","title":"Minimal Action Method using Optimal Control","text":"","category":"section"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"The Minimal Action Method is a numerical technique for finding the most probable transition pathway between stable states in stochastic dynamical systems. It achieves this by minimizing an action functional that represents the path's deviation from the deterministic dynamics, effectively identifying the path of least resistance through the system's landscape. This tutorial demonstrates how to implement MAM as an optimal control problem.","category":"page"},{"location":"tutorial-mam.html#Required-Packages","page":"Minimal action","title":"Required Packages","text":"","category":"section"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"using OptimalControl\nusing NLPModelsIpopt\nusing Plots, Printf","category":"page"},{"location":"tutorial-mam.html#Problem-Setup","page":"Minimal action","title":"Problem Setup","text":"","category":"section"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"We'll consider a 2D system with a double-well flow, called the Maier-Stein model. It is a famous benchmark problem as it exhibits non-gradient dynamics with two stable equilibrium points at (-1,0) and (1,0), connected by a non-trivial transition path. The system's deterministic dynamics are given by:","category":"page"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"# Define the vector field\nf(u, v) = [u - u^3 - 10*u*v^2,  -(1 - u^2)*v]\nf(x) = f(x...)\nnothing # hide","category":"page"},{"location":"tutorial-mam.html#Optimal-Control-Formulation","page":"Minimal action","title":"Optimal Control Formulation","text":"","category":"section"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"The minimal action path minimizes the deviation from the deterministic dynamics:","category":"page"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"function ocp(T)\n    action = @def begin\n        t ∈ [0, T], time\n        x ∈ R², state\n        u ∈ R², control\n        x(0) == [-1, 0]    # Starting point (left well)\n        x(T) == [1, 0]     # End point (right well)\n        ẋ(t) == u(t)       # Path dynamics\n        ∫( sum((u(t) - f(x(t))).^2) ) → min  # Minimize deviation from deterministic flow\n    end\n    return action\nend\nnothing # hide","category":"page"},{"location":"tutorial-mam.html#Initial-Guess","page":"Minimal action","title":"Initial Guess","text":"","category":"section"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"We provide an initial guess for the path using a simple interpolation:","category":"page"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"# Time horizon\nT = 50\n\n# Linear interpolation for x₁\nx1(t) = -(1 - t/T) + t/T\n\n# Parabolic guess for x₂\nx2(t) = 0.3(-x1(t)^2 + 1)\nx(t) = [x1(t), x2(t)]\nu(t) = f(x(t))\n\n# Initial guess\ninit = (state=x, control=u)\nnothing # hide","category":"page"},{"location":"tutorial-mam.html#Solving-the-Problem","page":"Minimal action","title":"Solving the Problem","text":"","category":"section"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"We solve the problem in two steps for better accuracy:","category":"page"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"# First solve with coarse grid\nsol = solve(ocp(T); init=init, grid_size=50)\n\n# Refine solution with finer grid\nsol = solve(ocp(T); init=sol, grid_size=1000)\n\n# Objective value\nobjective(sol)","category":"page"},{"location":"tutorial-mam.html#Visualizing-Results","page":"Minimal action","title":"Visualizing Results","text":"","category":"section"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"Let's plot the solution trajectory and phase space:","category":"page"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"plot(sol)","category":"page"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"# Phase space plot\nMLP = state(sol).(time_grid(sol))\nscatter(first.(MLP), last.(MLP), \n        title=\"Minimal Action Path\",\n        xlabel=\"u\",\n        ylabel=\"v\",\n        label=\"Transition path\")","category":"page"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"The resulting path shows the most likely transition between the two stable states given a transient time T=50, minimizing the action functional while respecting the system's dynamics.","category":"page"},{"location":"tutorial-mam.html#Minimize-with-respect-to-T","page":"Minimal action","title":"Minimize with respect to T","text":"","category":"section"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"To find the maximum likelihood path, we also need to minimize the transient time T. Hence, we perform a discrete continuation over the parameter T by solving the optimal control problem over a continuous range of final times T, using each solution to initialize the next problem.","category":"page"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"objectives = []\nTs = range(1,100,100)\nsol = solve(ocp(Ts[1]); display=false, init=init, grid_size=50)\nprintln(\" Time   Objective     Iterations\")\nfor T=Ts\n    global sol = solve(ocp(T); display=false, init=sol, grid_size=1000, tol=1e-8)\n    @printf(\"%6.2f  %9.6e  %d\\n\", T, objective(sol), iterations(sol))\n    push!(objectives, objective(sol))\nend","category":"page"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"T_min = Ts[argmin(objectives)]\nplt1 = scatter(Ts, log10.(objectives), xlabel=\"Time\", label=\"Objective (log10)\")\nvline!(plt1, [T_min], label=\"Minimum\", z_order=:back)\nplt2 = scatter(Ts[20:100], log10.(objectives[20:100]), xlabel=\"Time\", label=\"Objective (log10)\")\nvline!(plt2, [T_min], label=\"Minimum\", z_order=:back)\nplot(plt1, plt2, layout=(2,1), size=(800,800))","category":"page"},{"location":"tutorial-iss.html#tutorial-indirect-simple-shooting","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"","category":"section"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"In this tutorial we present the indirect simple shooting method on a simple example.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"Let us start by importing the necessary packages. We import the OptimalControl.jl package to define the optimal control problem.  We import the Plots.jl package to plot the solution.  The OrdinaryDiffEq.jl package is used to define the shooting function for the indirect method and the MINPACK.jl package permits to solve the shooting equation.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"using BenchmarkTools    # to benchmark the methods\nusing OptimalControl    # to define the optimal control problem and its flow\nusing OrdinaryDiffEq    # to get the Flow function from OptimalControl\nusing MINPACK           # NLE solver: use to solve the shooting equation\nusing NonlinearSolve    # interface to NLE solvers\nusing Plots             # to plot the solution","category":"page"},{"location":"tutorial-iss.html#Optimal-control-problem","page":"Indirect simple shooting","title":"Optimal control problem","text":"","category":"section"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"Let us consider the following optimal control problem:","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"left \n    beginarrayl\n        min displaystyle frac12 int_t_0^t_f u^2(t)  mathrmd t10em\n        dotx(t)  =  displaystyle -x(t)+alpha x^2(t)+u(t) quad  u(t) in R \n        quad t in t_0 t_f text ae 05em\n        x(t_0) = x_0 quad x(t_f) = x_f\n    endarray\nright","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"with t_0 = 0, t_f = 1, x_0 = -1, x_f = 0, alpha=15 and forall t in t_0 t_f, x(t) in R.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"const t0 = 0\nconst tf = 1\nconst x0 = -1\nconst xf = 0\nconst α  = 1.5\nocp = @def begin\n\n    t ∈ [t0, tf], time\n    x ∈ R, state\n    u ∈ R, control\n\n    x(t0) == x0\n    x(tf) == xf\n\n    ẋ(t) == -x(t) + α * x(t)^2 + u(t)\n\n    ∫( 0.5u(t)^2 ) → min\n    \nend\nnothing # hide","category":"page"},{"location":"tutorial-iss.html#Boundary-value-problem","page":"Indirect simple shooting","title":"Boundary value problem","text":"","category":"section"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"The pseudo-Hamiltonian of this problem is","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"    H(xpu) = p  (-x+alpha x^2+u) + p^0 u^2 2","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"where p^0 = -1 since we are in the normal case. From the Pontryagin Maximum Principle, the maximising control is given by","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"u(x p) = p","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"since partial^2_uu H = p^0 = - 1  0. Plugging this control in feedback form into the pseudo-Hamiltonian, and considering the limit conditions, we obtain the following two-points boundary value problem (BVP).","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"    left \n        beginarrayl\n            dotx(t)  = phantom- nabla_p Ht = -x(t) + alpha x^2(t) + u(x(t) p(t)) \n            = -x(t) + alpha x^2(t) + p(t) 05em\n            dotp(t)  = -           nabla_x Ht = (1 - 2 alpha x(t)) p(t)    05em\n            x(t_0)        = x_0 quad x(t_f) = x_f\n        endarray\n    right","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"where t=  (x(t)p(t)u(x(t) p(t))).","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"note: Our goal\nOur goal is to solve this boundary value problem (BVP), which is equivalent to solving the Pontryagin Maximum Principle (PMP), which provides necessary conditions for optimality.","category":"page"},{"location":"tutorial-iss.html#Shooting-function","page":"Indirect simple shooting","title":"Shooting function","text":"","category":"section"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"To achive our goal, let us first introduce the pseudo-Hamiltonian vector field","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"    vecH(zu) = left( nabla_p H(zu) -nabla_x H(zu) right) quad z = (xp)","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"and then denote by varphi_t_0 x_0 p_0(cdot) the solution of the following Cauchy problem","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"dotz(t) = vecH(z(t) u(z(t))) quad z(t_0) = (x_0 p_0)","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"Our goal becomes to solve","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"pi( varphi_t_0 x_0 p_0(t_f) ) = x_f","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"where pi(x p) = x. To compute varphi with OptimalControl.jl package, we define the flow of the associated Hamiltonian vector field by:","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"u(x, p) = p\nφ = Flow(ocp, u)\nnothing # hide","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"We define also the projection function on the state space.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"π((x, p)) = x\nnothing # hide","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"note: Nota bene\nActually, varphi_t_0 x_0 p_0(cdot) is also solution of    dotz(t) = vecmathbfH(z(t)) quad z(t_0) = (x_0 p_0)where mathbfH(z) = H(z u(z)) and vecmathbfH = (nabla_p mathbfH -nabla_x mathbfH). This is what is actually computed by Flow.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"Now, to solve the (BVP) we introduce the shooting function:","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"    beginarrayrlll\n        S colon     R     longrightarrow    R \n                     p_0     longmapsto      S(p_0) = pi( varphi_t_0 x_0 p_0(t_f) ) - x_f\n    endarray","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"S(p0) = π( φ(t0, x0, p0, tf) ) - xf    # shooting function\nnothing # hide","category":"page"},{"location":"tutorial-iss.html#Resolution-of-the-shooting-equation","page":"Indirect simple shooting","title":"Resolution of the shooting equation","text":"","category":"section"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"At the end, solving (BVP) is equivalent to solve S(p_0) = 0. This is what we call the indirect simple shooting method. We define an initial guess.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"ξ = [0.1]    # initial guess\nnothing # hide","category":"page"},{"location":"tutorial-iss.html#MINPACK.jl","page":"Indirect simple shooting","title":"MINPACK.jl","text":"","category":"section"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"We can use NonlinearSolve.jl package or, instead, MINPACK.jl to solve the shooting equation. To compute the Jacobian of the shooting function we use DifferentiationInterface.jl with ForwardDiff.jl backend.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"using DifferentiationInterface\nimport ForwardDiff\nbackend = AutoForwardDiff()\nnothing # hide","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"Let us define the problem to solve.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"nle!(s, ξ) = s[1] = S(ξ[1])                                 # auxiliary function\njnle!(js, ξ) = jacobian!(nle!, similar(ξ), js, backend, ξ)  # Jacobian of nle\nnothing # hide","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"We are now in position to solve the problem with the hybrj solver from MINPACK.jl through the fsolve function, providing the Jacobian. Let us solve the problem and retrieve the initial costate solution.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"sol = fsolve(nle!, jnle!, ξ; show_trace=true)    # resolution of S(p0) = 0\np0_sol = sol.x[1]                                # costate solution\nprintln(\"\\ncostate:    p0 = \", p0_sol)\nprintln(\"shoot: |S(p0)| = \", abs(S(p0_sol)), \"\\n\")","category":"page"},{"location":"tutorial-iss.html#NonlinearSolve.jl","page":"Indirect simple shooting","title":"NonlinearSolve.jl","text":"","category":"section"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"Alternatively, we can use the NonlinearSolve.jl package to solve the shooting equation. The code is similar, but we use the solve function instead of fsolve. Let us define the problem.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"nle!(s, ξ, λ) = s[1] = S(ξ[1])    # auxiliary function\nprob = NonlinearProblem(nle!, ξ)  # NLE problem with initial guess\nnothing # hide","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"Now, let us solve the problem and retrieve the initial costate solution.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"sol = solve(prob; show_trace=Val(true)) # resolution of S(p0) = 0  \np0_sol = sol.u[1] # costate solution\nprintln(\"\\ncostate:    p0 = \", p0_sol)\nprintln(\"shoot: |S(p0)| = \", abs(S(p0_sol)), \"\\n\")","category":"page"},{"location":"tutorial-iss.html#Benchmarking","page":"Indirect simple shooting","title":"Benchmarking","text":"","category":"section"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"Let us benchmark the methods to solve the shooting equation.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"@benchmark fsolve(nle!, jnle!, ξ; show_trace=false) # MINPACK","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"@benchmark solve(prob; show_trace=Val(false)) # NonlinearSolve","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"According to the NonlinearSolve documentation, for small nonlinear systems, it could be faster to use the  SimpleNewtonRaphson() descent algorithm. ","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"@benchmark solve(prob, SimpleNewtonRaphson(); show_trace=Val(false)) # NonlinearSolve","category":"page"},{"location":"tutorial-iss.html#Plot-of-the-solution","page":"Indirect simple shooting","title":"Plot of the solution","text":"","category":"section"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"The solution can be plot calling first the flow.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"sol = φ((t0, tf), x0, p0_sol)\nplot(sol)","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"In the indirect shooting method, the search for the optimal control is replaced by the computation of its associated extremal. This computation is equivalent to finding the initial costate (or covector) that solves the shooting function. Let us now plot the extremal trajectory in the phase space, along with the shooting function and its solution.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"<details><summary>Code of the plot function in the phase space.</summary>","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"using Plots.PlotMeasures \nfunction Plots.plot(S::Function, p0::Float64; Np0=20, kwargs...) \n \n    # times for wavefronts\n    times = range(t0, tf, length=3)\n\n    # times for trajectories\n    tspan = range(t0, tf, length=100)\n\n    # interval of initial covector\n    p0_min = -0.5 \n    p0_max = 2 \n\n    # covector solution\n    p0_sol = p0 \n \n    # plot of the flow in phase space\n    plt_flow = plot() \n    p0s = range(p0_min, p0_max, length=Np0) \n    for i ∈ eachindex(p0s) \n        sol = φ((t0, tf), x0, p0s[i])\n        x = state(sol).(tspan)\n        p = costate(sol).(tspan)\n        label = i==1 ? \"extremals\" : false \n        plot!(plt_flow, x, p, color=:blue, label=label) \n    end \n \n    # plot of wavefronts in phase space \n    p0s = range(p0_min, p0_max, length=200) \n    xs  = zeros(length(p0s), length(times)) \n    ps  = zeros(length(p0s), length(times)) \n    for i ∈ eachindex(p0s) \n        sol = φ((t0, tf), x0, p0s[i], saveat=times)\n        xs[i, :] .= state(sol).(times) \n        ps[i, :] .= costate(sol).(times) \n    end \n    for j ∈ eachindex(times) \n        label = j==1 ? \"flow at times\" : false \n        plot!(plt_flow, xs[:, j], ps[:, j], color=:green, linewidth=2, label=label) \n    end \n \n    #  \n    plot!(plt_flow, xlims=(-1.1, 1), ylims=(p0_min, p0_max)) \n    plot!(plt_flow, [0, 0], [p0_min, p0_max], color=:black, xlabel=\"x\", ylabel=\"p\", label=\"x=xf\") \n     \n    # solution \n    sol = φ((t0, tf), x0, p0_sol)\n    x = state(sol).(tspan)\n    p = costate(sol).(tspan)\n    plot!(plt_flow, x, p, color=:red, linewidth=2, label=\"extremal solution\") \n    plot!(plt_flow, [x[end]], [p[end]], seriestype=:scatter, color=:green, label=false) \n \n    # plot of the shooting function  \n    p0s = range(p0_min, p0_max, length=200) \n    plt_shoot = plot(xlims=(p0_min, p0_max), ylims=(-2, 4), xlabel=\"p₀\", ylabel=\"y\") \n    plot!(plt_shoot, p0s, S, linewidth=2, label=\"S(p₀)\", color=:green) \n    plot!(plt_shoot, [p0_min, p0_max], [0, 0], color=:black, label=\"y=0\") \n    plot!(plt_shoot, [p0_sol, p0_sol], [-2, 0], color=:black, label=\"p₀ solution\", linestyle=:dash) \n    plot!(plt_shoot, [p0_sol], [0], seriestype=:scatter, color=:green, label=false) \n \n    # final plot \n    plot(plt_flow, plt_shoot; layout=(1,2), leftmargin=15px, bottommargin=15px, kwargs...) \n \nend\nnothing # hide","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"</details>","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"plot(S, p0_sol; size=(800, 450))","category":"page"},{"location":"tutorial-lqr.html#A-simple-Linear–quadratic-regulator-example","page":"Linear–quadratic regulator","title":"A simple Linear–quadratic regulator example","text":"","category":"section"},{"location":"tutorial-lqr.html#Problem-statement","page":"Linear–quadratic regulator","title":"Problem statement","text":"","category":"section"},{"location":"tutorial-lqr.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"We consider the following Linear Quadratic Regulator (LQR) problem, which consists in minimizing","category":"page"},{"location":"tutorial-lqr.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"    frac12 int_0^t_f left( x_1^2(t) + x_2^2(t) + u^2(t) right)  mathrmdt ","category":"page"},{"location":"tutorial-lqr.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"subject to the dynamics","category":"page"},{"location":"tutorial-lqr.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"    dot x_1(t) = x_2(t) quad dot x_2(t) = -x_1(t) + u(t) quad u(t) in R","category":"page"},{"location":"tutorial-lqr.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"and the initial condition","category":"page"},{"location":"tutorial-lqr.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"    x(0) = (01)","category":"page"},{"location":"tutorial-lqr.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"We aim to solve this optimal control problem for different values of t_f.  ","category":"page"},{"location":"tutorial-lqr.html#Required-packages","page":"Linear–quadratic regulator","title":"Required packages","text":"","category":"section"},{"location":"tutorial-lqr.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"We begin by importing the necessary packages:","category":"page"},{"location":"tutorial-lqr.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"using OptimalControl\nusing NLPModelsIpopt\nusing Plots\nusing Plots.PlotMeasures # for leftmargin, bottommargin","category":"page"},{"location":"tutorial-lqr.html#Problem-definition","page":"Linear–quadratic regulator","title":"Problem definition","text":"","category":"section"},{"location":"tutorial-lqr.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"We define the LQR problem as a function of the final time tf:","category":"page"},{"location":"tutorial-lqr.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"function lqr(tf)\n\n    x0 = [ 0\n           1 ]\n\n    ocp = @def begin\n        t ∈ [0, tf], time\n        x ∈ R², state\n        u ∈ R, control\n        x(0) == x0\n        ẋ(t) == [x₂(t), - x₁(t) + u(t)]\n        0.5∫( x₁(t)^2 + x₂(t)^2 + u(t)^2 ) → min\n    end\n\n    return ocp\nend\nnothing # hide","category":"page"},{"location":"tutorial-lqr.html#Solving-the-problem-for-different-final-times","page":"Linear–quadratic regulator","title":"Solving the problem for different final times","text":"","category":"section"},{"location":"tutorial-lqr.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"We solve the problem for t_f in 3 5 30.","category":"page"},{"location":"tutorial-lqr.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"solutions = []   # empty list of solutions\ntfs = [3, 5, 30]\n\nfor tf ∈ tfs\n    solution = solve(lqr(tf), display=false)\n    push!(solutions, solution)\nend\nnothing # hide","category":"page"},{"location":"tutorial-lqr.html#Plotting-the-Solutions","page":"Linear–quadratic regulator","title":"Plotting the Solutions","text":"","category":"section"},{"location":"tutorial-lqr.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"We plot the state and control variables using normalized time s = (t - t_0)(t_f - t_0):","category":"page"},{"location":"tutorial-lqr.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"plt = plot(solutions[1], :state, :control; time=:normalize, label=\"tf = $(tfs[1])\")\nfor (tf, sol) ∈ zip(tfs[2:end], solutions[2:end])\n    plot!(plt, sol, :state, :control; time=:normalize, label=\"tf = $tf\")\nend\n\npx1 = plot(plt[1], legend=false, xlabel=\"s\", ylabel=\"x₁\")\npx2 = plot(plt[2], legend=true, xlabel=\"s\", ylabel=\"x₂\")\npu  = plot(plt[3], legend=false, xlabel=\"s\", ylabel=\"u\")\nplot(px1, px2, pu, layout=(1, 3), size=(800, 300), leftmargin=5mm, bottommargin=5mm)","category":"page"},{"location":"tutorial-lqr.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"note: Nota bene\nWe can observe that x(t_f) converges to the origin as t_f increases.","category":"page"},{"location":"tutorial-lqr.html#Limitations:-using-matrix-formulation","page":"Linear–quadratic regulator","title":"Limitations: using matrix formulation","text":"","category":"section"},{"location":"tutorial-lqr.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"The following definition will lead to an error when solving the problem:","category":"page"},{"location":"tutorial-lqr.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"\nx0 = [ 0\n       1 ]\n\nA = [  0 1\n      -1 0 ]\n\nB = [ 0\n      1 ]\n\nQ = [ 1 0\n      0 1 ]\n\nR = 1\n\ntf = 3\n\nocp = @def begin\n    t ∈ [0, tf], time\n    x ∈ R², state\n    u ∈ R, control\n    x(0) == x0\n    ẋ(t) == A * x(t) + B * u(t)\n    0.5∫( x(t)' * Q * x(t) + u(t)' * R * u(t) ) → min\nend\n\nsolve(ocp)","category":"page"},{"location":"tutorial-nlp.html#tutorial-nlp","page":"NLP manipulations","title":"NLP and DOCP manipulations","text":"","category":"section"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"We describe here some more advanced operations related to the discretized optimal control problem. When calling solve(ocp) three steps are performed internally:","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"first, the OCP is discretized into a DOCP (a nonlinear optimization problem),\nthen, this DOCP is solved with a nonlinear programming (NLP) solver, which returns a solution of the discretized problem,\nfinally, a functional solution of the OCP is rebuilt from the solution of the discretized problem.","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"These steps can also be done separately, for instance if you want to use your own NLP solver. ","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"Let us load the packages.","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"using OptimalControl\nusing Plots","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"We define a test problem","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"ocp = @def begin\n\n    t ∈ [0, 1], time\n    x ∈ R², state\n    u ∈ R, control\n\n    x(0) == [ -1, 0 ]\n    x(1) == [ 0, 0 ]\n\n    ẋ(t) == [ x₂(t), u(t) ]\n\n    ∫( 0.5u(t)^2 ) → min\n\nend\nnothing # hide","category":"page"},{"location":"tutorial-nlp.html#Discretization-and-NLP-problem","page":"NLP manipulations","title":"Discretization and NLP problem","text":"","category":"section"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"We discretize the problem.","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"docp, nlp = direct_transcription(ocp)\nnothing # hide","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"The DOCP contains information related to the transcription, including a copy of the original OCP, and the NLP is the resulting discretized problem, in our case an ADNLPModel.","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"We can now use the solver of our choice to solve it.","category":"page"},{"location":"tutorial-nlp.html#Resolution-of-the-NLP-problem","page":"NLP manipulations","title":"Resolution of the NLP problem","text":"","category":"section"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"For a first example we use the ipopt solver from NLPModelsIpopt.jl package to solve the NLP problem.","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"using NLPModelsIpopt\nnlp_sol = ipopt(nlp; print_level=5, mu_strategy=\"adaptive\", tol=1e-8, sb=\"yes\")\nnothing # hide","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"Then we can rebuild and plot an optimal control problem solution (note that the multipliers are optional, but the OCP costate will not be retrieved if the multipliers are not provided).","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"sol = build_OCP_solution(docp; primal=nlp_sol.solution, dual=nlp_sol.multipliers)\nplot(sol)","category":"page"},{"location":"tutorial-nlp.html#Change-the-NLP-solver","page":"NLP manipulations","title":"Change the NLP solver","text":"","category":"section"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"Alternatively, we can use MadNLP.jl to solve anew the NLP problem:","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"using MadNLP\nnlp_sol = madnlp(nlp)","category":"page"},{"location":"tutorial-nlp.html#Initial-guess","page":"NLP manipulations","title":"Initial guess","text":"","category":"section"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"An initial guess, including warm start, can be passed to direct_transcription the same way as for solve.","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"docp, nlp = direct_transcription(ocp; init=sol)\nnothing # hide","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"It can also be changed after the transcription is done, with  set_initial_guess.","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"set_initial_guess(docp, nlp, sol)\nnothing # hide","category":"page"},{"location":"tutorial-continuation.html#Discrete-continuation","page":"Discrete continuation","title":"Discrete continuation","text":"","category":"section"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"By using the warm start option, it is easy to implement a basic discrete continuation method, in which a sequence of problems is solved by using each solution as the initial guess for the next problem. This approach typically leads to faster and more reliable convergence than solving each problem with the same initial guess and is particularly useful for problems that require a good initial guess to converge.","category":"page"},{"location":"tutorial-continuation.html#Continuation-on-parametric-OCP","page":"Discrete continuation","title":"Continuation on parametric OCP","text":"","category":"section"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"The most concise way to perform discrete continuation is to define a function that returns the optimal control problem for a given value of the continuation parameter, and then solve a sequence of such problems. We illustrate this using a simple double integrator problem, where the fixed final time is gradually increased.","category":"page"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"First we load the required packages:","category":"page"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"using DataFrames\nusing OptimalControl\nusing NLPModelsIpopt\nusing Printf\nusing Plots","category":"page"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"and write a function that returns the OCP for a given final time:","category":"page"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"function problem(T)\n\n    ocp = @def begin\n\n        t ∈ [0, T], time\n        x ∈ R², state\n        u ∈ R, control\n\n        q = x₁\n        v = x₂\n\n        q(0) == 0\n        v(0) == 0\n        q(T) == 1\n        v(T) == 0\n        ẋ(t) == [v(t), u(t)]\n\n        ∫(u(t)^2) → min\n\n    end\n\n    return ocp\nend\nnothing # hide","category":"page"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"Then we perform the continuation with a simple for loop, using each solution to initialize the next problem.","category":"page"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"init = ()\ndata = DataFrame(T=Float64[], Objective=Float64[], Iterations=Int[])\nfor T ∈ range(1, 2, length=5)\n    ocp = problem(T) \n    sol = solve(ocp; init=init, display=false)\n    global init = sol\n    push!(data, (T=T, Objective=objective(sol), Iterations=iterations(sol)))\nend\nprintln(data)","category":"page"},{"location":"tutorial-continuation.html#Continuation-on-global-variable","page":"Discrete continuation","title":"Continuation on global variable","text":"","category":"section"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"As a second example, we show how to avoid redefining a new optimal control problem at each step by modifying the original one instead. More precisely, we solve a Goddard problem with a decreasing maximum thrust. By storing the value of Tmax in a global variable, we can simply update this variable and reuse the same problem throughout the continuation.","category":"page"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"Let us first define the Goddard problem. Note that the formulation below illustrates all types of constraints, and the problem could be written more compactly.","category":"page"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"# Parameters\nr0 = 1\nv0 = 0\nm0 = 1\nmf = 0.6\nx0 = [r0, v0, m0]\nvmax = 0.1\n\n# Goddard problem definition\n@def goddard begin\n\n    tf ∈ R, variable\n    t ∈ [0, tf], time\n    x ∈ R^3, state\n    u ∈ R, control\n\n    0.01 ≤ tf ≤ Inf\n\n    r = x[1]\n    v = x[2]\n    m = x[3]\n    x(0) == x0\n    m(tf) == mf\n    r0 ≤ r(t) ≤ r0 + 0.1\n    v0 ≤ v(t) ≤ vmax\n    mf ≤ m(t) ≤ m0\n    0 ≤ u(t) ≤ 1\n    ẋ(t) == F0(x(t)) + u(t) * F1(x(t))\n\n    r(tf) → max\n\nend\n\n# Dynamics\nfunction F0(x)\n    r, v, m = x\n    D = Cd * v^2 * exp(-β*(r - 1))\n    return [ v, -D/m - 1/r^2, 0 ]\nend\nfunction F1(x)\n    r, v, m = x\n    return [ 0, Tmax/m, -b*Tmax ]\nend\n\n# Parameters for the dynamics\nCd = 310\nβ = 500\nb = 2\nTmax_0 = 3.5\nTmax_f = 1.0\n\n# Solve the problem with a reference value of Tmax\nTmax = Tmax_0\nsol0 = solve(goddard; display=false)\n@printf(\"Objective for reference solution: %.6f\\n\", objective(sol0))","category":"page"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"Then, we perform the continuation on the maximal thrust.","category":"page"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"sol = sol0 # Initialize the solution with the reference solution\ndata = DataFrame(Tmax=Float64[], Objective=Float64[], Iterations=Int[])\nfor Tmax_local ∈ range(Tmax_0, Tmax_f, length=6)\n    global Tmax = Tmax_local # Update the global variable Tmax\n    global sol = solve(goddard; init=sol, display=false)\n    push!(data, (Tmax=Tmax, Objective=objective(sol), Iterations=iterations(sol)))\nend \nprintln(data)","category":"page"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"We plot now the objective with respect to the maximal thrust, as well as both solutions for Tmax=3.5 and Tmax=1.","category":"page"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"using Plots.PlotMeasures # for leftmargin\n\nplt_obj = plot(data.Tmax, data.Objective;\n    seriestype=:scatter,\n    title=\"Goddard problem\",\n    label=\"r(tf)\", \n    xlabel=\"Maximal thrust (Tmax)\",\n    ylabel=\"Maximal altitude r(tf)\")\n\nplt_sol = plot(sol0; label=\"Tmax=\"*string(data.Tmax[1]))\nplot!(plt_sol, sol;  label=\"Tmax=\"*string(data.Tmax[end]))\n\nlayout = grid(2, 1, heights=[0.2, 0.8])\nplot(plt_obj, plt_sol; layout=layout, size=(800, 1000), leftmargin=5mm)","category":"page"},{"location":"index.html#Tutorials","page":"Getting Started","title":"Tutorials","text":"","category":"section"},{"location":"index.html","page":"Getting Started","title":"Getting Started","text":"This collection of tutorials is part of the control-toolbox ecosystem. The control-toolbox ecosystem gathers Julia packages for mathematical control and applications. It aims to provide tools to model and solve optimal control problems with ordinary differential equations by direct and indirect methods. If you want to define an optimal control problem and solve it, please check the documentation.","category":"page"},{"location":"index.html","page":"Getting Started","title":"Getting Started","text":"From this page, you can find a list of tutorials to solve optimal control problems with OptimalControl.","category":"page"},{"location":"index.html#Reproducibility","page":"Getting Started","title":"Reproducibility","text":"","category":"section"},{"location":"index.html","page":"Getting Started","title":"Getting Started","text":"<details><summary>The documentation of this package was built using these direct dependencies,</summary>","category":"page"},{"location":"index.html","page":"Getting Started","title":"Getting Started","text":"using Pkg # hide\nPkg.status() # hide","category":"page"},{"location":"index.html","page":"Getting Started","title":"Getting Started","text":"</details>","category":"page"},{"location":"index.html","page":"Getting Started","title":"Getting Started","text":"<details><summary>and using this machine and Julia version.</summary>","category":"page"},{"location":"index.html","page":"Getting Started","title":"Getting Started","text":"using InteractiveUtils # hide\nversioninfo() # hide","category":"page"},{"location":"index.html","page":"Getting Started","title":"Getting Started","text":"</details>","category":"page"},{"location":"index.html","page":"Getting Started","title":"Getting Started","text":"<details><summary>A more complete overview of all dependencies and their versions is also provided.</summary>","category":"page"},{"location":"index.html","page":"Getting Started","title":"Getting Started","text":"using Pkg # hide\nPkg.status(; mode = PKGMODE_MANIFEST) # hide","category":"page"},{"location":"index.html","page":"Getting Started","title":"Getting Started","text":"</details>","category":"page"},{"location":"index.html","page":"Getting Started","title":"Getting Started","text":"using TOML\nusing Markdown\nversion = TOML.parse(read(\"../../Project.toml\", String))[\"version\"]\nname = TOML.parse(read(\"../../Project.toml\", String))[\"name\"]\nlink_manifest = \"https://github.com/control-toolbox/\" *\n                name *\n                \".jl/tree/gh-pages/v\" *\n                version *\n                \"/assets/Manifest.toml\"\nlink_project = \"https://github.com/control-toolbox/\" *\n               name *\n               \".jl/tree/gh-pages/v\" *\n               version *\n               \"/assets/Project.toml\"\nMarkdown.parse(\"\"\"You can also download the\n[manifest]($link_manifest)\nfile and the\n[project]($link_project)\nfile.\n\"\"\")","category":"page"},{"location":"tutorial-goddard.html#tutorial-goddard","page":"Goddard: direct, indirect","title":"Direct and indirect methods for the Goddard problem","text":"","category":"section"},{"location":"tutorial-goddard.html#Introduction","page":"Goddard: direct, indirect","title":"Introduction","text":"","category":"section"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"<img src=\"./assets/Goddard_and_Rocket.jpg\" style=\"float: left; margin: auto 10px;\" width=\"200px\">","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"For this example, we consider the well-known Goddard problem[1] [2] which models the ascent of a rocket through the atmosphere, and we restrict here ourselves to vertical (one dimensional) trajectories. The state variables are the altitude r, speed v and mass m of the rocket during the flight, for a total dimension of 3. The rocket is subject to gravity g, thrust u and drag force D (function of speed and altitude). The final time t_f is free, and the objective is to reach a maximal altitude with a bounded fuel consumption.","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"We thus want to solve the optimal control problem in Mayer form","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"    r(t_f) to max","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"subject to the controlled dynamics","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"    dotr = v quad\n    dotv = fracT_maxu - D(rv)m - g quad\n    dotm = -u","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"and subject to the control constraint u(t) in 01 and the state constraint v(t) leq v_max. The initial state is fixed while only the final mass is prescribed.","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"note: Nota bene\nThe Hamiltonian is affine with respect to the control, so singular arcs may occur, as well as constrained arcs due to the path constraint on the velocity (see below).","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"We import the OptimalControl.jl package to define the optimal control problem and NLPModelsIpopt.jl to solve it.  We import the Plots.jl package to plot the solution.  The OrdinaryDiffEq.jl package is used to  define the shooting function for the indirect method and the MINPACK.jl package permits to solve the shooting equation.","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"using OptimalControl  # to define the optimal control problem and more\nusing NLPModelsIpopt  # to solve the problem via a direct method\nusing OrdinaryDiffEq  # to get the Flow function from OptimalControl\nusing MINPACK         # NLE solver: use to solve the shooting equation\nusing Plots           # to plot the solution","category":"page"},{"location":"tutorial-goddard.html#Optimal-control-problem","page":"Goddard: direct, indirect","title":"Optimal control problem","text":"","category":"section"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"We define the problem","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"const t0 = 0      # initial time\nconst r0 = 1      # initial altitude\nconst v0 = 0      # initial speed\nconst m0 = 1      # initial mass\nconst vmax = 0.1  # maximal authorized speed\nconst mf = 0.6    # final mass to target\n\nocp = @def begin # definition of the optimal control problem\n\n    tf ∈ R, variable\n    t ∈ [t0, tf], time\n    x = (r, v, m) ∈ R³, state\n    u ∈ R, control\n\n    x(t0) == [r0, v0, m0]\n    m(tf) == mf,         (1)\n    0 ≤ u(t) ≤ 1\n    r(t) ≥ r0\n    0 ≤ v(t) ≤ vmax\n\n    ẋ(t) == F0(x(t)) + u(t) * F1(x(t))\n\n    r(tf) → max\n\nend\n\n# Dynamics\nconst Cd = 310\nconst Tmax = 3.5\nconst β = 500\nconst b = 2\n\nF0(x) = begin\n    r, v, m = x\n    D = Cd * v^2 * exp(-β*(r - 1)) # Drag force\n    return [v, -D/m - 1/r^2, 0]\nend\n\nF1(x) = begin\n    r, v, m = x\n    return [0, Tmax/m, -b*Tmax]\nend\nnothing # hide","category":"page"},{"location":"tutorial-goddard.html#Direct-method","page":"Goddard: direct, indirect","title":"Direct method","text":"","category":"section"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"We then solve it","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"direct_sol = solve(ocp; grid_size=100)\nnothing # hide","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"and plot the solution","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"plt = plot(direct_sol, label=\"direct\", size=(800, 800))","category":"page"},{"location":"tutorial-goddard.html#tutorial-goddard-structure","page":"Goddard: direct, indirect","title":"Structure of the solution","text":"","category":"section"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"We first determine visually the structure of the optimal solution which is composed of a bang arc with maximal control, followed by a singular arc, then by a boundary arc and the final arc is with zero control. Note that the switching function vanishes along the singular and boundary arcs.","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"t = time_grid(direct_sol)   # the time grid as a vector\nx = state(direct_sol)       # the state as a function of time\nu = control(direct_sol)     # the control as a function of time\np = costate(direct_sol)     # the costate as a function of time\n\nH1 = Lift(F1)           # H1(x, p) = p' * F1(x)\nφ(t) = H1(x(t), p(t))   # switching function\ng(x) = vmax - x[2]      # state constraint v ≤ vmax\n\nu_plot  = plot(t, u,     label = \"u(t)\")\nH1_plot = plot(t, φ,     label = \"H₁(x(t), p(t))\")\ng_plot  = plot(t, g ∘ x, label = \"g(x(t))\")\n\nplot(u_plot, H1_plot, g_plot, layout=(3,1), size=(500, 500))","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"We are now in position to solve the problem by an indirect shooting method. We first define the four control laws in feedback form and their associated flows. For this we need to compute some Lie derivatives, namely Poisson brackets of Hamiltonians (themselves obtained as lifts to the cotangent bundle of vector fields), or derivatives of functions along a vector field. For instance, the control along the minimal order singular arcs is obtained as the quotient","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"u_s = -fracH_001H_101","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"of length three Poisson brackets:","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"H_001 = H_0H_0H_1 quad H_101 = H_1H_0H_1","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"where, for two Hamiltonians H and G,","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"HG = (nabla_p Hnabla_x G) - (nabla_x Hnabla_p G)","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"While the Lie derivative of a function f wrt. a vector field X is simply obtained as","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"(X cdot f)(x) = f(x) cdot X(x)","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"and is used to the compute the control along the boundary arc,","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"u_b(x) = -(F_0 cdot g)(x)  (F_1 cdot g)(x)","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"as well as the associated multiplier for the order one state constraint on the velocity:","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"mu(x p) = H_01(x p)  (F_1 cdot g)(x)","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"note: Poisson bracket and Lie derivative\nThe Poisson bracket HG is also given by the Lie derivative of G along the Hamiltonian vector field X_H = (nabla_p H -nabla_x H) of H, that is    HG = X_H cdot Gwhich is the reason why we use the @Lie macro to compute Poisson brackets below.","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"With the help of differential geometry primitives, these expressions are straightforwardly translated into Julia code:","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"# Controls\nconst u0 = 0                            # off control\nconst u1 = 1                            # bang control\n\nH0 = Lift(F0)                           # H0(x, p) = p' * F0(x)\nH01  = @Lie {H0, H1}\nH001 = @Lie {H0, H01}\nH101 = @Lie {H1, H01}\nus(x, p) = -H001(x, p) / H101(x, p)     # singular control\n\nub(x) = -(F0⋅g)(x) / (F1⋅g)(x)          # boundary control\nμ(x, p) = H01(x, p) / (F1⋅g)(x)         # multiplier associated to the state constraint g\n\n# Flows\nf0 = Flow(ocp, (x, p, tf) -> u0)\nf1 = Flow(ocp, (x, p, tf) -> u1)\nfs = Flow(ocp, (x, p, tf) -> us(x, p))\nfb = Flow(ocp, (x, p, tf) -> ub(x), (x, u, tf) -> g(x), (x, p, tf) -> μ(x, p))\nnothing # hide","category":"page"},{"location":"tutorial-goddard.html#Shooting-function","page":"Goddard: direct, indirect","title":"Shooting function","text":"","category":"section"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"Then, we define the shooting function according to the optimal structure we have determined, that is a concatenation of four arcs.","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"x0 = [r0, v0, m0] # initial state\n\nfunction shoot!(s, p0, t1, t2, t3, tf)\n\n    x1, p1 = f1(t0, x0, p0, t1)\n    x2, p2 = fs(t1, x1, p1, t2)\n    x3, p3 = fb(t2, x2, p2, t3)\n    xf, pf = f0(t3, x3, p3, tf)\n\n    s[1] = xf[3] - mf                             # final mass constraint\n    s[2:3] = pf[1:2] - [1, 0]                     # transversality conditions\n    s[4] = H1(x1, p1)                             # H1 = H01 = 0\n    s[5] = H01(x1, p1)                            # at the entrance of the singular arc\n    s[6] = g(x2)                                  # g = 0 when entering the boundary arc\n    s[7] = H0(xf, pf)                             # since tf is free\n\nend\nnothing # hide","category":"page"},{"location":"tutorial-goddard.html#Initial-guess","page":"Goddard: direct, indirect","title":"Initial guess","text":"","category":"section"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"To solve the problem by an indirect shooting method, we then need a good initial guess, that is a good approximation of the initial costate, the three switching times and the final time.","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"η = 1e-3\nt13 = t[ abs.(φ.(t)) .≤ η ]\nt23 = t[ 0 .≤ (g ∘ x).(t) .≤ η ]\np0 = p(t0)\nt1 = min(t13...)\nt2 = min(t23...)\nt3 = max(t23...)\ntf = t[end]\n\nprintln(\"p0 = \", p0)\nprintln(\"t1 = \", t1)\nprintln(\"t2 = \", t2)\nprintln(\"t3 = \", t3)\nprintln(\"tf = \", tf)\n\n# Norm of the shooting function at solution\nusing LinearAlgebra: norm\ns = similar(p0, 7)\nshoot!(s, p0, t1, t2, t3, tf)\nprintln(\"\\nNorm of the shooting function: ‖s‖ = \", norm(s), \"\\n\")","category":"page"},{"location":"tutorial-goddard.html#Indirect-shooting","page":"Goddard: direct, indirect","title":"Indirect shooting","text":"","category":"section"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"We aggregate the data to define the initial guess vector.","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"ξ = [p0..., t1, t2, t3, tf] # initial guess","category":"page"},{"location":"tutorial-goddard.html#MINPACK.jl","page":"Goddard: direct, indirect","title":"MINPACK.jl","text":"","category":"section"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"We can use NonlinearSolve.jl package or, instead, the  MINPACK.jl package to solve  the shooting equation. To compute the Jacobian of the shooting function we use the  DifferentiationInterface.jl package with  ForwardDiff.jl backend.","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"using DifferentiationInterface\nimport ForwardDiff\nbackend = AutoForwardDiff()\nnothing # hide","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"Let us define the problem to solve.","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"# auxiliary function with aggregated inputs\nnle!  = ( s, ξ) -> shoot!(s, ξ[1:3], ξ[4], ξ[5], ξ[6], ξ[7])\n\n# Jacobian of the (auxiliary) shooting function\njnle! = (js, ξ) -> jacobian!(nle!, similar(ξ), js, backend, ξ)\nnothing # hide","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"We are now in position to solve the problem with the hybrj solver from MINPACK.jl through the fsolve  function, providing the Jacobian. Let us solve the problem and retrieve the initial costate solution.","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"# resolution of S(ξ) = 0\nindirect_sol = fsolve(nle!, jnle!, ξ, show_trace=true)\n\n# we retrieve the costate solution together with the times\np0 = indirect_sol.x[1:3]\nt1 = indirect_sol.x[4]\nt2 = indirect_sol.x[5]\nt3 = indirect_sol.x[6]\ntf = indirect_sol.x[7]\n\nprintln(\"\")\nprintln(\"p0 = \", p0)\nprintln(\"t1 = \", t1)\nprintln(\"t2 = \", t2)\nprintln(\"t3 = \", t3)\nprintln(\"tf = \", tf)\n\n# Norm of the shooting function at solution\ns = similar(p0, 7)\nshoot!(s, p0, t1, t2, t3, tf)\nprintln(\"\\nNorm of the shooting function: ‖s‖ = \", norm(s), \"\\n\")","category":"page"},{"location":"tutorial-goddard.html#tutorial-goddard-plot","page":"Goddard: direct, indirect","title":"Plot of the solution","text":"","category":"section"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"We plot the solution of the indirect solution (in red) over the solution of the direct method  (in blue).","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"f = f1 * (t1, fs) * (t2, fb) * (t3, f0) # concatenation of the flows\nflow_sol = f((t0, tf), x0, p0)          # compute the solution: state, costate, control...\n\nplot!(plt, flow_sol, label=\"indirect\")","category":"page"},{"location":"tutorial-goddard.html#References","page":"Goddard: direct, indirect","title":"References","text":"","category":"section"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"[1]: R.H. Goddard. A Method of Reaching Extreme Altitudes, volume 71(2) of Smithsonian Miscellaneous Collections. Smithsonian institution, City of Washington, 1919.","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"[2]: H. Seywald and E.M. Cliff. Goddard problem in presence of a dynamic pressure limit. Journal of Guidance, Control, and Dynamics, 16(4):776–781, 1993.","category":"page"},{"location":"tutorial-mpc.html#Navigation-problem,-MPC-approach","page":"Model Predictive Control","title":"Navigation problem, MPC approach","text":"","category":"section"},{"location":"tutorial-mpc.html","page":"Model Predictive Control","title":"Model Predictive Control","text":"We consider a ship in a constant current w=(w_xw_y), where w1.  The heading angle is controlled, leading to the following differential equations:","category":"page"},{"location":"tutorial-mpc.html","page":"Model Predictive Control","title":"Model Predictive Control","text":"beginarrayrcl\n    dotx(t) = w_x + costheta(t) quad t in 0 t_f \n    doty(t) = w_y + sintheta(t) \n    dottheta(t) = u(t) \nendarray","category":"page"},{"location":"tutorial-mpc.html","page":"Model Predictive Control","title":"Model Predictive Control","text":"The angular velocity is limited and normalized: u(t) leq 1. There are boundary conditions at the initial time t=0 and at the final time t=t_f, on the position (xy) and on the angle theta. The objective is to minimize the final time. This topic stems from a collaboration between the University Côte d'Azur and the French company CGG, which is interested in optimal maneuvers of very large ships for marine exploration.","category":"page"},{"location":"tutorial-mpc.html","page":"Model Predictive Control","title":"Model Predictive Control","text":"<img \n      src=\"./assets/ship.jpg\"\n      style=\"display: block;\n      margin-left: auto;\n      margin-right: auto;\n      width: 50%;\"\n>","category":"page"},{"location":"tutorial-mpc.html#Data","page":"Model Predictive Control","title":"Data","text":"","category":"section"},{"location":"tutorial-mpc.html","page":"Model Predictive Control","title":"Model Predictive Control","text":"using LinearAlgebra\nusing NLPModelsIpopt\nusing OptimalControl\nusing OrdinaryDiffEq\nusing Plots\nusing Plots.PlotMeasures\nusing Printf\n\nt0 = 0.\nx0 = 0. \ny0 = 0.\nθ0 = π/7\nxf = 4.\nyf = 7.\nθf = -π/2\n\nfunction current(x, y) # current as a function of position\n    ε = 1e-1\n    w = [ 0.6, 0.4 ]\n    δw = ε * [ y, -x ] / sqrt(1+x^2+y^2)\n    w = w + δw\n    if (w[1]^2 + w[2]^2 >= 1)\n        error(\"|w| >= 1\")\n    end\n    return w\nend\n\n#\nfunction plot_state!(plt, x, y, θ; color=1)\n    plot!(plt, [x], [y], marker=:circle, legend=false, color=color, markerstrokecolor=color, markersize=5, z_order=:front)\n    quiver!(plt, [x], [y], quiver=([cos(θ)], [sin(θ)]), color=color, linewidth=2, z_order=:front)\n    return plt\nend\n\nfunction plot_current!(plt; current=current, N=10, scaling=1)\n    for x ∈ range(xlims(plt)..., N)\n        for y ∈ range(ylims(plt)..., N)\n            w = scaling*current(x, y)\n            quiver!(plt, [x], [y], quiver=([w[1]], [w[2]]), color=:black, linewidth=0.5, z_order=:back)\n        end\n    end\n    return plt\nend\n\n# Display the boundary conditions and the current in the augmented phase plane\nplt = plot(\n    xlims=(-2, 6), \n    ylims=(-1, 8), \n    size=(600, 600), \n    aspect_ratio=1, \n    xlabel=\"x\", \n    ylabel=\"y\", \n    title=\"Boundary Conditions\",\n    leftmargin=5mm, \n    bottommargin=5mm,\n)\n\nplot_state!(plt, x0, y0, θ0; color=2)\nplot_state!(plt, xf, yf, θf; color=2)\nannotate!([(x0, y0, (\"q₀\", 12, :top)), (xf, yf, (\"qf\", 12, :bottom))])\nplot_current!(plt)","category":"page"},{"location":"tutorial-mpc.html","page":"Model Predictive Control","title":"Model Predictive Control","text":"function plot_trajectory!(plt, t, x, y, θ; N=5) # N: number of points where we will display θ\n\n    # trajectory\n    plot!(plt, x.(t), y.(t), legend=false, color=1, linewidth=2, z_order=:front)\n\n    if N > 0\n\n        # length of the path\n        s = 0\n        for i ∈ 2:length(t)\n            s += norm([x(t[i]), y(t[i])] - [x(t[i-1]), y(t[i-1])])\n        end\n\n        # interval of length\n        Δs = s/(N+1)\n        tis = []\n        s = 0\n        for i ∈ 2:length(t)\n            s += norm([x(t[i]), y(t[i])] - [x(t[i-1]), y(t[i-1])])\n            if s > Δs && length(tis) < N\n                push!(tis, t[i])\n                s = 0\n            end\n        end\n\n        # display intermediate points\n        for ti ∈ tis\n            plot_state!(plt, x(ti), y(ti), θ(ti); color=1)\n        end\n\n    end\n\n    return plt\n    \nend\nnothing # hide","category":"page"},{"location":"tutorial-mpc.html#OptimalControl-solver","page":"Model Predictive Control","title":"OptimalControl solver","text":"","category":"section"},{"location":"tutorial-mpc.html","page":"Model Predictive Control","title":"Model Predictive Control","text":"function solve(t0, x0, y0, θ0, xf, yf, θf, w; \n    grid_size=300, tol=1e-8, max_iter=500, print_level=4, display=true, disc_method=:euler)\n\n    # Definition of the problem\n    ocp = @def begin\n\n        tf ∈ R, variable\n        t ∈ [t0, tf], time\n        q = (x, y, θ) ∈ R³, state\n        u ∈ R, control\n\n        -1 ≤ u(t) ≤ 1\n\n        -2 ≤ x(t) ≤ 6\n        -2 ≤ y(t) ≤ 8\n        -2π ≤ x(t) ≤ 2π\n\n        q(t0) == [x0, y0, θ0]\n        q(tf) == [xf, yf, θf]\n\n        q̇(t) == [w[1]+cos(θ(t)), \n                  w[2]+sin(θ(t)), \n                  u(t)]\n\n        tf → min\n\n    end\n\n    # Initialization\n    tf_init = 1.5*norm([xf, yf]-[x0, y0])\n    x_init(t) = [ x0, y0, θ0 ] * (tf_init-t)/(tf_init-t0) + [xf, yf, θf] * (t-t0)/(tf_init-t0)\n    u_init = (θf - θ0) / (tf_init-t0)\n    init = (state=x_init, control=u_init, variable=tf_init)\n\n    # Resolution\n    sol = OptimalControl.solve(ocp; \n        init=init,\n        grid_size=grid_size, \n        tol=tol, \n        max_iter=max_iter, \n        print_level=print_level, \n        display=display, \n        disc_method=disc_method,\n    )\n\n    # Retrieval of useful data\n    t = time_grid(sol)\n    q = state(sol)\n    x = t -> q(t)[1]\n    y = t -> q(t)[2]\n    θ = t -> q(t)[3]\n    u = control(sol)\n    tf = variable(sol)\n    \n    return t, x, y, θ, u, tf, iterations(sol), sol.solver_infos.constraints_violation\n    \nend\nnothing # hide","category":"page"},{"location":"tutorial-mpc.html#First-resolution","page":"Model Predictive Control","title":"First resolution","text":"","category":"section"},{"location":"tutorial-mpc.html","page":"Model Predictive Control","title":"Model Predictive Control","text":"We consider a constant current and we solve a first time the problem.","category":"page"},{"location":"tutorial-mpc.html","page":"Model Predictive Control","title":"Model Predictive Control","text":"# Resolution\nt, x, y, θ, u, tf, iter, cons = solve(t0, x0, y0, θ0, xf, yf, θf, current(x0, y0); display=false);\n\nprintln(\"Iterations: \", iter)\nprintln(\"Constraints violation: \", cons)\nprintln(\"tf: \", tf)","category":"page"},{"location":"tutorial-mpc.html","page":"Model Predictive Control","title":"Model Predictive Control","text":"# Displaying the trajectory\nplt_q = plot(xlims=(-2, 6), ylims=(-1, 8), aspect_ratio=1, xlabel=\"x\", ylabel=\"y\")\nplot_state!(plt_q, x0, y0, θ0; color=2)\nplot_state!(plt_q, xf, yf, θf; color=2)\nplot_current!(plt_q; current=(x, y) -> current(x0, y0))\nplot_trajectory!(plt_q, t, x, y, θ)\n\n# Displaying the control\nplt_u = plot(t, u; color=1, legend=false, linewidth=2, xlabel=\"t\", ylabel=\"u\")\n\n# Final display\nplot(plt_q, plt_u; \n    layout=(1, 2), \n    size=(1200, 600),\n    leftmargin=5mm, \n    bottommargin=5mm,\n    plot_title=\"Constant Current Simulation\"\n)","category":"page"},{"location":"tutorial-mpc.html#Simulation-of-the-Real-System","page":"Model Predictive Control","title":"Simulation of the Real System","text":"","category":"section"},{"location":"tutorial-mpc.html","page":"Model Predictive Control","title":"Model Predictive Control","text":"In the previous simulation, we assumed that the current is constant. However, from a practical standpoint, the current depends on the position (x y). Given a current model, provided by the function current, we can simulate the actual trajectory of the ship, as long as we have the initial condition and the control over time.","category":"page"},{"location":"tutorial-mpc.html","page":"Model Predictive Control","title":"Model Predictive Control","text":"function realistic_trajectory(tf, t0, x0, y0, θ0, u, current; abstol=1e-12, reltol=1e-12, saveat=[])\n    \n    function rhs!(dq, q, dummy, t)\n        x, y, θ = q\n        w = current(x, y)\n        dq[1] = w[1] + cos(θ)\n        dq[2] = w[2] + sin(θ)\n        dq[3] = u(t)\n    end\n    \n    q0 = [x0, y0, θ0]\n    tspan = (t0, tf)\n    ode = ODEProblem(rhs!, q0, tspan)\n    sol = OrdinaryDiffEq.solve(ode, Tsit5(), abstol=abstol, reltol=reltol, saveat=saveat)\n\n    t = sol.t\n    x = t -> sol(t)[1]\n    y = t -> sol(t)[2]\n    θ = t -> sol(t)[3]\n\n    return t, x, y, θ\n    \nend\nnothing # hide","category":"page"},{"location":"tutorial-mpc.html","page":"Model Predictive Control","title":"Model Predictive Control","text":"# Realistic trajectory\nt, x, y, θ = realistic_trajectory(tf, t0, x0, y0, θ0, u, current)\n\n# Displaying the trajectory\nplt_q = plot(xlims=(-2, 6), ylims=(-1, 8), aspect_ratio=1, xlabel=\"x\", ylabel=\"y\")\nplot_state!(plt_q, x0, y0, θ0; color=2)\nplot_state!(plt_q, xf, yf, θf; color=2)\nplot_current!(plt_q; current=current)\nplot_trajectory!(plt_q, t, x, y, θ)\nplot_state!(plt_q, x(tf), y(tf), θ(tf); color=3)\n\n# Displaying the control\nplt_u = plot(t, u; color=1, legend=false, linewidth=2, xlabel=\"t\", ylabel=\"u\")\n\n# Final display\nplot(plt_q, plt_u; \n    layout=(1, 2), \n    size=(1200, 600),\n    leftmargin=5mm, \n    bottommargin=5mm,\n    plot_title=\"Simulation with Current Model\"\n)","category":"page"},{"location":"tutorial-mpc.html#MPC-Approach","page":"Model Predictive Control","title":"MPC Approach","text":"","category":"section"},{"location":"tutorial-mpc.html","page":"Model Predictive Control","title":"Model Predictive Control","text":"In practice, we do not have the actual current data for the entire trajectory in advance, which is why we will regularly recalculate the optimal control. The idea is to update the optimal control at regular time intervals, taking into account the current at the position where the ship is located. We are therefore led to solve a number of problems with constant current, with this being updated regularly. This is an introduction to the so-called Model Predictive Control (MPC) methods.","category":"page"},{"location":"tutorial-mpc.html","page":"Model Predictive Control","title":"Model Predictive Control","text":"function MPC(t0, x0, y0, θ0, xf, yf, θf, current)\n\n    Nmax = 20   # maximum number of iterations for the MPC method\n    ε = 1e-1    # radius on the final condition to stop calculations\n    Δt = 1.0    # fixed time step for the MPC method\n    P = 300      # number of discretization points for the solver\n\n    t1 = t0\n    x1 = x0\n    y1 = y0\n    θ1 = θ0\n\n    data = []\n\n    N = 1\n    stop = false\n\n    while !stop\n        \n        # Retrieve the current at the current position\n        w = current(x1, y1)\n\n        # Solve the problem\n        t, x, y, θ, u, tf, iter, cons = solve(t1, x1, y1, θ1, xf, yf, θf, w; grid_size=P, display=false);\n\n        # Calculate the next time\n        if (t1 + Δt < tf)\n            t2 = t1 + Δt\n        else\n            t2 = tf\n            stop = true\n        end\n\n        # Store the data: the current initial time, the next time, the control\n        push!(data, (t2, t1, x(t1), y(t1), θ(t1), u, tf))\n\n        # Update the parameters of the MPC method: simulate reality\n        t, x, y, θ = realistic_trajectory(t2, t1, x1, y1, θ1, u, current)\n        t1 = t2\n        x1 = x(t1)\n        y1 = y(t1)\n        θ1 = θ(t1)\n\n        # Calculate the distance to the target position\n        distance = norm([x1, y1, θ1] - [xf, yf, θf])\n        if N == 1\n            println(\"     N    Distance  Iterations   Constraints       tf\")\n            println(\"------------------------------------------------------\")\n        end\n        @printf(\"%6d\", N)\n        @printf(\"%12.4f\", distance)\n        @printf(\"%12d\", iter)\n        @printf(\"%14.4e\", cons)\n        @printf(\"%10.4f\\n\", tf)\n        if !((distance > ε) && (N < Nmax))\n            stop = true\n        end\n\n        #\n        N += 1\n\n    end\n\n    return data\nend\n\ndata = MPC(t0, x0, y0, θ0, xf, yf, θf, current)\nnothing # hide","category":"page"},{"location":"tutorial-mpc.html#Display","page":"Model Predictive Control","title":"Display","text":"","category":"section"},{"location":"tutorial-mpc.html","page":"Model Predictive Control","title":"Model Predictive Control","text":"# Trajectory\nplt_q = plot(xlims=(-2, 6), ylims=(-1, 8), aspect_ratio=1, xlabel=\"x\", ylabel=\"y\")\n\n# Final condition\nplot_state!(plt_q, xf, yf, θf; color=2)\n\n# Current\nplot_current!(plt_q; current=current)\n\n# Control\nplt_u = plot(xlabel=\"t\", ylabel=\"u\")\n\nfor d ∈ data\n\n    t2, t1, x1, y1, θ1, u, tf = d\n\n    # Calculate the actual trajectory\n    t, x, y, θ = realistic_trajectory(t2, t1, x1, y1, θ1, u, current)\n\n    # Trajectory\n    plot_state!(plt_q, x1, y1, θ1; color=2)\n    plot_trajectory!(plt_q, t, x, y, θ; N=0)\n\n    # Control\n    plot!(plt_u, t, u; color=1, legend=false, linewidth=2)\n\nend\n\n# last point\nd = data[end]\nt2, t1, x1, y1, θ1, u, tf = d\nt, x, y, θ = realistic_trajectory(t2, t1, x1, y1, θ1, u, current)\nplot_state!(plt_q, x(tf), y(tf), θ(tf); color=3)\n\n#\nplot(plt_q, plt_u; \n    layout=(1, 2), \n    size=(1200, 600),\n    leftmargin=5mm, \n    bottommargin=5mm,\n    plot_title=\"Simulation with Current Model\"\n)","category":"page"},{"location":"tutorial-mpc.html#Limitations","page":"Model Predictive Control","title":"Limitations","text":"","category":"section"},{"location":"tutorial-mpc.html","page":"Model Predictive Control","title":"Model Predictive Control","text":"If you use a discretization method other than :euler, the solver may converge to a local solution that is not globally optimal.","category":"page"},{"location":"tutorial-mpc.html","page":"Model Predictive Control","title":"Model Predictive Control","text":"# Resolution\nt, x, y, θ, u, tf, iter, cons = solve(t0, x0, y0, θ0, xf, yf, θf, current(x0, y0); \n    display=false, disc_method=:gauss_legendre_3);\n\nprintln(\"Iterations: \", iter)\nprintln(\"Constraints violation: \", cons)\nprintln(\"tf: \", tf)","category":"page"},{"location":"tutorial-mpc.html","page":"Model Predictive Control","title":"Model Predictive Control","text":"# Displaying the trajectory\nplt_q = plot(xlims=(-2, 6), ylims=(-1, 8), aspect_ratio=1, xlabel=\"x\", ylabel=\"y\")\nplot_state!(plt_q, x0, y0, θ0; color=2)\nplot_state!(plt_q, xf, yf, θf; color=2)\nplot_current!(plt_q; current=(x, y) -> current(x0, y0))\nplot_trajectory!(plt_q, t, x, y, θ)\n\n# Displaying the control\nplt_u = plot(t, u; color=1, legend=false, linewidth=2, xlabel=\"t\", ylabel=\"u\")\n\n# Final display\nplot(plt_q, plt_u; \n    layout=(1, 2), \n    size=(1200, 600),\n    leftmargin=5mm, \n    bottommargin=5mm,\n    plot_title=\"Constant Current Simulation\"\n)","category":"page"}]
}
