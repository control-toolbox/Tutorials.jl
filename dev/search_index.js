var documenterSearchIndex = {"docs":
[{"location":"tutorial-discretisation.html#tutorial-discretisation-methods","page":"Discretisation methods","title":"Discretisation methods","text":"","category":"section"},{"location":"tutorial-discretisation.html#Discretisation-formulas","page":"Discretisation methods","title":"Discretisation formulas","text":"","category":"section"},{"location":"tutorial-discretisation.html","page":"Discretisation methods","title":"Discretisation methods","text":"When calling solve, the option disc_method=... can be used to set the discretisation scheme. In addition to the default implicit :trapeze method (aka Crank-Nicolson), other choices are available, namely implicit :midpoint and the Gauss-Legendre collocations with 2 and  stages, :gauss_legendre_2 and :gauss_legendre_3, of order 4 and 6 respectively.  Note that higher order methods will typically lead to larger NLP problems for the same number of time steps, and that accuracy will also depend on the smoothness of the problem.","category":"page"},{"location":"tutorial-discretisation.html","page":"Discretisation methods","title":"Discretisation methods","text":"As an example we will use the Goddard problem.","category":"page"},{"location":"tutorial-discretisation.html","page":"Discretisation methods","title":"Discretisation methods","text":"using OptimalControl  # to define the optimal control problem and more\nusing NLPModelsIpopt  # to solve the problem via a direct method\nusing Plots           # to plot the solution\n\nt0 = 0      # initial time\nr0 = 1      # initial altitude\nv0 = 0      # initial speed\nm0 = 1      # initial mass\nvmax = 0.1  # maximal authorized speed\nmf = 0.6    # final mass to target\n\nocp = @def begin # definition of the optimal control problem\n\n    tf ∈ R, variable\n    t ∈ [t0, tf], time\n    x = (r, v, m) ∈ R³, state\n    u ∈ R, control\n\n    x(t0) == [ r0, v0, m0 ]\n    m(tf) == mf,         (1)\n    0 ≤ u(t) ≤ 1\n    r(t) ≥ r0\n    0 ≤ v(t) ≤ vmax\n\n    ẋ(t) == F0(x(t)) + u(t) * F1(x(t))\n\n    r(tf) → max\n\nend;\n\n# Dynamics\nconst Cd = 310\nconst Tmax = 3.5\nconst β = 500\nconst b = 2\n\nF0(x) = begin\n    r, v, m = x\n    D = Cd * v^2 * exp(-β*(r - 1)) # Drag force\n    return [ v, -D/m - 1/r^2, 0 ]\nend\n\nF1(x) = begin\n    r, v, m = x\n    return [ 0, Tmax/m, -b*Tmax ]\nend\nnothing # hide","category":"page"},{"location":"tutorial-discretisation.html","page":"Discretisation methods","title":"Discretisation methods","text":"Now let us compare different discretisations","category":"page"},{"location":"tutorial-discretisation.html","page":"Discretisation methods","title":"Discretisation methods","text":"x_style = (legend=:none,)\np_style = (legend=:none,)\n\nsol_trapeze = solve(ocp; tol=1e-8)\nplt = plot(sol_trapeze; label=\"trapeze\", state_style=x_style, costate_style=p_style)\n\nsol_midpoint = solve(ocp, disc_method=:midpoint; tol=1e-8)\nplot!(plt, sol_midpoint; label=\"midpoint\", state_style=x_style, costate_style=p_style);\n\nsol_euler = solve(ocp, disc_method=:euler; tol=1e-8)\nplot!(plt, sol_euler; label=\"euler\", state_style=x_style, costate_style=p_style);\n\nsol_euler_imp = solve(ocp, disc_method=:euler_implicit; tol=1e-8)\nplot!(plt, sol_euler_imp; label=\"euler implicit\", state_style=x_style, costate_style=p_style);\n\nsol_gl2 = solve(ocp, disc_method=:gauss_legendre_2; tol=1e-8)\nplot!(plt, sol_gl2; label=\"gauss legendre 2\", state_style=x_style, costate_style=p_style);\n\nsol_gl3 = solve(ocp, disc_method=:gauss_legendre_3; tol=1e-8)\nplot!(plt, sol_gl3; label=\"gauss legendre 3\", state_style=x_style, costate_style=p_style);\n\nplot(plt, size=(800, 800))","category":"page"},{"location":"tutorial-discretisation.html#Large-problems-and-AD-backend","page":"Discretisation methods","title":"Large problems and AD backend","text":"","category":"section"},{"location":"tutorial-discretisation.html","page":"Discretisation methods","title":"Discretisation methods","text":"For some large problems, you may notice that solving spends a long time before the iterations actually begin. This is due to the computing of the sparse derivatives, namely the Jacobian of the constraints and the Hessian of the Lagrangian, that can become quite costly. A possible alternative is to set the option adnlp_backend=:manual, which will use more basic sparsity patterns. The resulting matrices are faster to compute but are also less sparse, so this is a trade-off bewteen the AD preparation and the optimization itself.","category":"page"},{"location":"tutorial-discretisation.html","page":"Discretisation methods","title":"Discretisation methods","text":"solve(ocp, disc_method=:gauss_legendre_3, grid_size=1000, adnlp_backend=:manual)\nnothing # hide","category":"page"},{"location":"tutorial-discretisation.html#Explicit-time-grid","page":"Discretisation methods","title":"Explicit time grid","text":"","category":"section"},{"location":"tutorial-discretisation.html","page":"Discretisation methods","title":"Discretisation methods","text":"The option time_grid=... allows to pass the complete time grid vector t0, t1, ..., tf, which is typically useful if one wants a non uniform grid.  In the case of a free initial and/or final time, provide a normalised grid between 0 and 1.  Note that time_grid will override grid_size if both are present.","category":"page"},{"location":"tutorial-discretisation.html","page":"Discretisation methods","title":"Discretisation methods","text":"sol = solve(ocp, time_grid=[0, 0.1, 0.5, 0.9, 1], display=false)\nprintln(time_grid(sol))","category":"page"},{"location":"tutorial-lqr-basic.html#A-simple-Linear–quadratic-regulator-example","page":"Linear–quadratic regulator","title":"A simple Linear–quadratic regulator example","text":"","category":"section"},{"location":"tutorial-lqr-basic.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"We consider the following Linear Quadratic Regulator (LQR) problem which consists in minimising","category":"page"},{"location":"tutorial-lqr-basic.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"    frac12 int_0^t_f left( x_1^2(t) + x_2^2(t) + u^2(t) right)  mathrmdt ","category":"page"},{"location":"tutorial-lqr-basic.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"subject to the constraints","category":"page"},{"location":"tutorial-lqr-basic.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"    dot x_1(t) = x_2(t) quad dot x_2(t) = -x_1(t) + u(t) quad u(t) in R","category":"page"},{"location":"tutorial-lqr-basic.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"and the initial condition","category":"page"},{"location":"tutorial-lqr-basic.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"    x(0) = (01)","category":"page"},{"location":"tutorial-lqr-basic.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"We aim to solve this optimal control problem for different values of t_f. First, we need to import the OptimalControl.jl package to define the  optimal control problem and NLPModelsIpopt.jl to solve it.  We also need to import the Plots.jl package to plot the solution.","category":"page"},{"location":"tutorial-lqr-basic.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"using OptimalControl\nusing NLPModelsIpopt\nusing Plots","category":"page"},{"location":"tutorial-lqr-basic.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"Then, we can define the problem parameterized by the final time tf.","category":"page"},{"location":"tutorial-lqr-basic.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"x0 = [ 0\n       1 ]\n\nfunction lqr(tf)\n\n    ocp = @def begin\n        t ∈ [0, tf], time\n        x ∈ R², state\n        u ∈ R, control\n        x(0) == x0\n        ẋ(t) == [x₂(t), - x₁(t) + u(t)]\n        ∫( 0.5(x₁(t)^2 + x₂(t)^2 + u(t)^2) ) → min\n    end\n\n    return ocp\nend;\nnothing # hide","category":"page"},{"location":"tutorial-lqr-basic.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"We solve the problem for t_f in 3 5 30.","category":"page"},{"location":"tutorial-lqr-basic.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"solutions = []   # empty list of solutions\ntfs = [3, 5, 30]\n\nfor tf ∈ tfs\n    solution = solve(lqr(tf), display=false)\n    push!(solutions, solution)\nend\nnothing # hide","category":"page"},{"location":"tutorial-lqr-basic.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"We plot the state and control variables considering a normalized time s=(t-t_0)(t_f-t_0), thanks to the keyword argument time=:normalize of the plot function.","category":"page"},{"location":"tutorial-lqr-basic.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"plt = plot(solutions[1], time=:normalize)\nfor sol ∈ solutions[2:end]\n    plot!(plt, sol, time=:normalize)\nend\n\n# we plot only the state and control variables and we add the legend\nN = length(tfs)\npx1 = plot(plt[1], legend=false, xlabel=\"s\", ylabel=\"x₁\")\npx2 = plot(plt[2], label=reshape([\"tf = $tf\" for tf ∈ tfs], (1, N)), xlabel=\"s\", ylabel=\"x₂\")\npu  = plot(plt[5], legend=false, xlabel=\"s\", ylabel=\"u\")\n\nusing Plots.PlotMeasures # for leftmargin, bottommargin\nplot(px1, px2, pu, layout=(1, 3), size=(800, 300), leftmargin=5mm, bottommargin=5mm)","category":"page"},{"location":"tutorial-lqr-basic.html","page":"Linear–quadratic regulator","title":"Linear–quadratic regulator","text":"note: Nota bene\nWe can observe that x(t_f) converges to the origin as t_f increases.","category":"page"},{"location":"tutorial-mam.html#Minimal-Action-Method-using-Optimal-Control","page":"Minimal action","title":"Minimal Action Method using Optimal Control","text":"","category":"section"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"The Minimal Action Method is a numerical technique for finding the most probable transition pathway between stable states in stochastic dynamical systems. It achieves this by minimizing an action functional that represents the path's deviation from the deterministic dynamics, effectively identifying the path of least resistance through the system's landscape. This tutorial demonstrates how to implement MAM as an optimal control problem.","category":"page"},{"location":"tutorial-mam.html#Required-Packages","page":"Minimal action","title":"Required Packages","text":"","category":"section"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"using OptimalControl\nusing NLPModelsIpopt\nusing Plots, Printf","category":"page"},{"location":"tutorial-mam.html#Problem-Setup","page":"Minimal action","title":"Problem Setup","text":"","category":"section"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"We'll consider a 2D system with a double-well flow, called the Maier-Stein model. It is a famous benchmark problem as it exhibits non-gradient dynamics with two stable equilibrium points at (-1,0) and (1,0), connected by a non-trivial transition path. The system's deterministic dynamics are given by:","category":"page"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"# Define the vector field\nf(u, v) = [u - u^3 - 10*u*v^2,  -(1 - u^2)*v]\nf(x) = f(x...)\nnothing # hide","category":"page"},{"location":"tutorial-mam.html#Optimal-Control-Formulation","page":"Minimal action","title":"Optimal Control Formulation","text":"","category":"section"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"The minimal action path minimizes the deviation from the deterministic dynamics:","category":"page"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"function ocp(T)\n    action = @def begin\n        t ∈ [0, T], time\n        x ∈ R², state\n        u ∈ R², control\n        x(0) == [-1, 0]    # Starting point (left well)\n        x(T) == [1, 0]     # End point (right well)\n        ẋ(t) == u(t)       # Path dynamics\n        ∫( sum((u(t) - f(x(t))).^2) ) → min  # Minimize deviation from deterministic flow\n    end\n    return action\nend\nnothing # hide","category":"page"},{"location":"tutorial-mam.html#Initial-Guess","page":"Minimal action","title":"Initial Guess","text":"","category":"section"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"We provide an initial guess for the path using a simple interpolation:","category":"page"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"# Time horizon\nT = 50\n\n# Linear interpolation for x₁\nx1(t) = -(1 - t/T) + t/T\n\n# Parabolic guess for x₂\nx2(t) = 0.3(-x1(t)^2 + 1)\nx(t) = [x1(t), x2(t)]\nu(t) = f(x(t))\n\n# Initial guess\ninit = (state=x, control=u)\nnothing # hide","category":"page"},{"location":"tutorial-mam.html#Solving-the-Problem","page":"Minimal action","title":"Solving the Problem","text":"","category":"section"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"We solve the problem in two steps for better accuracy:","category":"page"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"# First solve with coarse grid\nsol = solve(ocp(T); init=init, grid_size=50)\n\n# Refine solution with finer grid\nsol = solve(ocp(T); init=sol, grid_size=1000)\n\n# Objective value\nobjective(sol)","category":"page"},{"location":"tutorial-mam.html#Visualizing-Results","page":"Minimal action","title":"Visualizing Results","text":"","category":"section"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"Let's plot the solution trajectory and phase space:","category":"page"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"plot(sol)","category":"page"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"# Phase space plot\nMLP = state(sol).(time_grid(sol))\nscatter(first.(MLP), last.(MLP), \n        title=\"Minimal Action Path\",\n        xlabel=\"u\",\n        ylabel=\"v\",\n        label=\"Transition path\")","category":"page"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"The resulting path shows the most likely transition between the two stable states given a transient time T=50, minimizing the action functional while respecting the system's dynamics.","category":"page"},{"location":"tutorial-mam.html#Minimize-with-respect-to-T","page":"Minimal action","title":"Minimize with respect to T","text":"","category":"section"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"To find the maximum likelihood path, we also need to minimize the transient time T. Hence, we perform a discrete continuation over the parameter T by solving the optimal control problem over a continuous range of final times T, using each solution to initialize the next problem.","category":"page"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"objectives = []\nTs = range(1,100,100)\nsol = solve(ocp(Ts[1]); display=false, init=init, grid_size=50)\nprintln(\" Time   Objective     Iterations\")\nfor T=Ts\n    global sol = solve(ocp(T); display=false, init=sol, grid_size=1000, tol=1e-8)\n    @printf(\"%6.2f  %9.6e  %d\\n\", T, objective(sol), iterations(sol))\n    push!(objectives, objective(sol))\nend","category":"page"},{"location":"tutorial-mam.html","page":"Minimal action","title":"Minimal action","text":"T_min = Ts[argmin(objectives)]\nplt1 = scatter(Ts, log10.(objectives), xlabel=\"Time\", label=\"Objective (log10)\")\nvline!(plt1, [T_min], label=\"Minimum\", z_order=:back)\nplt2 = scatter(Ts[20:100], log10.(objectives[20:100]), xlabel=\"Time\", label=\"Objective (log10)\")\nvline!(plt2, [T_min], label=\"Minimum\", z_order=:back)\nplot(plt1, plt2, layout=(2,1), size=(800,800))","category":"page"},{"location":"tutorial-iss.html#tutorial-indirect-simple-shooting","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"","category":"section"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"In this tutorial we present the indirect simple shooting method on a simple example.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"Let us start by importing the necessary packages. We import the OptimalControl.jl package to define the optimal control problem.  We import the Plots.jl package to plot the solution.  The OrdinaryDiffEq.jl package is used to define the shooting function for the indirect method and the MINPACK.jl package permits to solve the shooting equation.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"using OptimalControl    # to define the optimal control problem and its flow\nusing OrdinaryDiffEq    # to get the Flow function from OptimalControl\nusing MINPACK           # NLE solver: use to solve the shooting equation\nusing Plots             # to plot the solution","category":"page"},{"location":"tutorial-iss.html#Optimal-control-problem","page":"Indirect simple shooting","title":"Optimal control problem","text":"","category":"section"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"Let us consider the following optimal control problem:","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"left \n    beginarrayl\n        min displaystyle frac12 int_t_0^t_f u^2(t)  mathrmd t10em\n        dotx(t)  =  displaystyle -x(t)+alpha x^2(t)+u(t) quad  u(t) in R \n        quad t in t_0 t_f text ae 05em\n        x(t_0) = x_0 quad x(t_f) = x_f\n    endarray\nright","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"with t_0 = 0, t_f = 1, x_0 = -1, x_f = 0, alpha=15 and forall t in t_0 t_f, x(t) in R.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"const t0 = 0\nconst tf = 1\nconst x0 = -1\nconst xf = 0\nconst α  = 1.5\nocp = @def begin\n\n    t ∈ [t0, tf], time\n    x ∈ R, state\n    u ∈ R, control\n\n    x(t0) == x0\n    x(tf) == xf\n\n    ẋ(t) == -x(t) + α * x(t)^2 + u(t)\n\n    ∫( 0.5u(t)^2 ) → min\n    \nend\nnothing # hide","category":"page"},{"location":"tutorial-iss.html#Boundary-value-problem","page":"Indirect simple shooting","title":"Boundary value problem","text":"","category":"section"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"The pseudo-Hamiltonian of this problem is","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"    H(xpu) = p  (-x+alpha x^2+u) + p^0 u^2 2","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"where p^0 = -1 since we are in the normal case. From the Pontryagin Maximum Principle, the maximising control is given by","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"u(x p) = p","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"since partial^2_uu H = p^0 = - 1  0. Plugging this control in feedback form into the pseudo-Hamiltonian, and considering the limit conditions, we obtain the following two-points boundary value problem (BVP).","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"    left \n        beginarrayl\n            dotx(t)  = phantom- nabla_p Ht = -x(t) + alpha x^2(t) + u(x(t) p(t)) \n            = -x(t) + alpha x^2(t) + p(t) 05em\n            dotp(t)  = -           nabla_x Ht = (1 - 2 alpha x(t)) p(t)    05em\n            x(t_0)        = x_0 quad x(t_f) = x_f\n        endarray\n    right","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"where t=  (x(t)p(t)u(x(t) p(t))).","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"note: Our goal\nOur goal is to solve this (BVP). Solving (BVP) consists in solving the Pontryagin Maximum Principle which provides necessary conditions of optimality.","category":"page"},{"location":"tutorial-iss.html#Shooting-function","page":"Indirect simple shooting","title":"Shooting function","text":"","category":"section"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"To achive our goal, let us first introduce the pseudo-Hamiltonian vector field","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"    vecH(zu) = left( nabla_p H(zu) -nabla_x H(zu) right) quad z = (xp)","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"and then denote by varphi_t_0 x_0 p_0(cdot) the solution of the following Cauchy problem","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"dotz(t) = vecH(z(t) u(z(t))) quad z(t_0) = (x_0 p_0)","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"Our goal becomes to solve","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"pi( varphi_t_0 x_0 p_0(t_f) ) = x_f","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"where pi(x p) = x. To compute varphi with OptimalControl.jl package, we define the flow of the associated Hamiltonian vector field by:","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"u(x, p) = p\nφ = Flow(ocp, u)\nnothing # hide","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"We define also the projection function on the state space.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"π((x, p)) = x\nnothing # hide","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"note: Nota bene\nActually, varphi_t_0 x_0 p_0(cdot) is also solution of    dotz(t) = vecmathbfH(z(t)) quad z(t_0) = (x_0 p_0)where mathbfH(z) = H(z u(z)) and vecmathbfH = (nabla_p mathbfH -nabla_x mathbfH). This is what is actually computed by Flow.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"Now, to solve the (BVP) we introduce the shooting function:","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"    beginarrayrlll\n        S colon     R     longrightarrow    R \n                     p_0     longmapsto      S(p_0) = pi( varphi_t_0 x_0 p_0(t_f) ) - x_f\n    endarray","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"S(p0) = π( φ(t0, x0, p0, tf) ) - xf    # shooting function\nnothing # hide","category":"page"},{"location":"tutorial-iss.html#Resolution-of-the-shooting-equation","page":"Indirect simple shooting","title":"Resolution of the shooting equation","text":"","category":"section"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"At the end, solving (BVP) is equivalent to solve S(p_0) = 0. This is what we call the indirect simple shooting method. We define an initial guess.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"ξ = [0.1]    # initial guess\nnothing # hide","category":"page"},{"location":"tutorial-iss.html#MINPACK.jl","page":"Indirect simple shooting","title":"MINPACK.jl","text":"","category":"section"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"We can use NonlinearSolve.jl package or, instead, MINPACK.jl to solve the shooting equation. To compute the Jacobian of the shooting function we use DifferentiationInterface.jl with ForwardDiff.jl backend.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"using DifferentiationInterface\nimport ForwardDiff\nbackend = AutoForwardDiff()\nnothing # hide","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"Let us define the problem to solve.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"nle!  = ( s, ξ) -> s[1] = S(ξ[1])                                 # auxiliary function\njnle! = (js, ξ) -> jacobian!(nle!, similar(ξ), js, backend, ξ)    # Jacobian of nle\nnothing # hide","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"We are now in position to solve the problem with the hybrj solver from MINPACK.jl through the fsolve function, providing the Jacobian. Let us solve the problem and retrieve the initial costate solution.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"indirect_sol = fsolve(nle!, jnle!, ξ; show_trace=true)    # resolution of S(p0) = 0\np0_sol = indirect_sol.x[1]                                # costate solution\nprintln(\"\\ncostate:    p0 = \", p0_sol)\nprintln(\"shoot: |S(p0)| = \", abs(S(p0_sol)), \"\\n\")","category":"page"},{"location":"tutorial-iss.html#Plot-of-the-solution","page":"Indirect simple shooting","title":"Plot of the solution","text":"","category":"section"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"The solution can be plot calling first the flow.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"sol = φ((t0, tf), x0, p0_sol)\nplot(sol)","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"In the indirect shooting method, the research of the optimal control is replaced by the computation of its associated extremal. This computation is equivalent to finding the initial covector solution to the shooting function. Let us plot the extremal in the phase space and the shooting function with  the solution.","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"<article class=\"docstring\">\n<header>\n    <a class=\"docstring-article-toggle-button fa-solid fa-chevron-right\" href=\"javascript:;\" title=\"Expand docstring\"> </a>\n    <code>pretty_plot</code> — <span class=\"docstring-category\">Function</span>\n</header>\n<section style=\"display: none;\"><div><pre><code class=\"language-julia hljs\">using Plots.PlotMeasures\n\nfunction pretty_plot(S, p0; Np0=20, kwargs...) \n \n    # times for wavefronts\n    times = range(t0, tf, length=3)\n\n    # times for trajectories\n    tspan = range(t0, tf, length=100)\n\n    # interval of initial covector\n    p0_min = -0.5 \n    p0_max = 2 \n\n    # covector solution\n    p0_sol = p0 \n \n    # plot of the flow in phase space\n    plt_flow = plot() \n    p0s = range(p0_min, p0_max, length=Np0) \n    for i ∈ eachindex(p0s) \n        sol = φ((t0, tf), x0, p0s[i])\n        x = state(sol).(tspan)\n        p = costate(sol).(tspan)\n        label = i==1 ? \"extremals\" : false \n        plot!(plt_flow, x, p, color=:blue, label=label) \n    end \n \n    # plot of wavefronts in phase space \n    p0s = range(p0_min, p0_max, length=200) \n    xs  = zeros(length(p0s), length(times)) \n    ps  = zeros(length(p0s), length(times)) \n    for i ∈ eachindex(p0s) \n        sol = φ((t0, tf), x0, p0s[i], saveat=times)\n        xs[i, :] .= state(sol).(times) \n        ps[i, :] .= costate(sol).(times) \n    end \n    for j ∈ eachindex(times) \n        label = j==1 ? \"flow at times\" : false \n        plot!(plt_flow, xs[:, j], ps[:, j], color=:green, linewidth=2, label=label) \n    end \n \n    #  \n    plot!(plt_flow, xlims=(-1.1, 1), ylims=(p0_min, p0_max)) \n    plot!(plt_flow, [0, 0], [p0_min, p0_max], color=:black, xlabel=\"x\", ylabel=\"p\", label=\"x=xf\") \n     \n    # solution \n    sol = φ((t0, tf), x0, p0_sol)\n    x = state(sol).(tspan)\n    p = costate(sol).(tspan)\n    plot!(plt_flow, x, p, color=:red, linewidth=2, label=\"extremal solution\") \n    plot!(plt_flow, [x[end]], [p[end]], seriestype=:scatter, color=:green, label=false) \n \n    # plot of the shooting function  \n    p0s = range(p0_min, p0_max, length=200) \n    plt_shoot = plot(xlims=(p0_min, p0_max), ylims=(-2, 4), xlabel=\"p₀\", ylabel=\"y\") \n    plot!(plt_shoot, p0s, S, linewidth=2, label=\"S(p₀)\", color=:green) \n    plot!(plt_shoot, [p0_min, p0_max], [0, 0], color=:black, label=\"y=0\") \n    plot!(plt_shoot, [p0_sol, p0_sol], [-2, 0], color=:black, label=\"p₀ solution\", linestyle=:dash) \n    plot!(plt_shoot, [p0_sol], [0], seriestype=:scatter, color=:green, label=false) \n \n    # final plot \n    plot(plt_flow, plt_shoot; layout=(1,2), leftmargin=15px, bottommargin=15px, kwargs...) \n \nend</code><button class=\"copy-button fa-solid fa-copy\" aria-label=\"Copy this code ;opblock\" title=\"Copy\"></button></pre></div>\n</section>\n</article>","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"using Plots.PlotMeasures # hide\nfunction pretty_plot(S, p0; Np0=20, kwargs...) # hide\n # hide\n    # times for wavefronts# hide\n    times = range(t0, tf, length=3)# hide\n# hide\n    # times for trajectories# hide\n    tspan = range(t0, tf, length=100)# hide\n# hide\n    # interval of initial covector# hide\n    p0_min = -0.5 # hide\n    p0_max = 2 # hide\n# hide\n    # covector solution# hide\n    p0_sol = p0 # hide\n # hide\n    # plot of the flow in phase space# hide\n    plt_flow = plot() # hide\n    p0s = range(p0_min, p0_max, length=Np0) # hide\n    for i ∈ eachindex(p0s) # hide\n        sol = φ((t0, tf), x0, p0s[i])# hide\n        x = state(sol).(tspan)# hide\n        p = costate(sol).(tspan)# hide\n        label = i==1 ? \"extremals\" : false # hide\n        plot!(plt_flow, x, p, color=:blue, label=label) # hide\n    end # hide\n # hide\n    # plot of wavefronts in phase space # hide\n    p0s = range(p0_min, p0_max, length=200) # hide\n    xs  = zeros(length(p0s), length(times)) # hide\n    ps  = zeros(length(p0s), length(times)) # hide\n    for i ∈ eachindex(p0s) # hide\n        sol = φ((t0, tf), x0, p0s[i], saveat=times)# hide\n        xs[i, :] .= state(sol).(times) # hide\n        ps[i, :] .= costate(sol).(times) # hide\n    end # hide\n    for j ∈ eachindex(times) # hide\n        label = j==1 ? \"flow at times\" : false # hide\n        plot!(plt_flow, xs[:, j], ps[:, j], color=:green, linewidth=2, label=label) # hide\n    end # hide\n # hide\n    #  # hide\n    plot!(plt_flow, xlims=(-1.1, 1), ylims=(p0_min, p0_max)) # hide\n    plot!(plt_flow, [0, 0], [p0_min, p0_max], color=:black, xlabel=\"x\", ylabel=\"p\", label=\"x=xf\") # hide\n     # hide\n    # solution # hide\n    sol = φ((t0, tf), x0, p0_sol)# hide\n    x = state(sol).(tspan)# hide\n    p = costate(sol).(tspan)# hide\n    plot!(plt_flow, x, p, color=:red, linewidth=2, label=\"extremal solution\") # hide\n    plot!(plt_flow, [x[end]], [p[end]], seriestype=:scatter, color=:green, label=false) # hide\n # hide\n    # plot of the shooting function  # hide\n    p0s = range(p0_min, p0_max, length=200) # hide\n    plt_shoot = plot(xlims=(p0_min, p0_max), ylims=(-2, 4), xlabel=\"p₀\", ylabel=\"y\") # hide\n    plot!(plt_shoot, p0s, S, linewidth=2, label=\"S(p₀)\", color=:green) # hide\n    plot!(plt_shoot, [p0_min, p0_max], [0, 0], color=:black, label=\"y=0\") # hide\n    plot!(plt_shoot, [p0_sol, p0_sol], [-2, 0], color=:black, label=\"p₀ solution\", linestyle=:dash) # hide\n    plot!(plt_shoot, [p0_sol], [0], seriestype=:scatter, color=:green, label=false) # hide\n # hide\n    # final plot # hide\n    plot(plt_flow, plt_shoot; layout=(1,2), leftmargin=15px, bottommargin=15px, kwargs...) # hide\n # hide\nend# hide\nnothing # hide","category":"page"},{"location":"tutorial-iss.html","page":"Indirect simple shooting","title":"Indirect simple shooting","text":"pretty_plot(S, p0_sol; size=(800, 450))","category":"page"},{"location":"tutorial-nlp.html#NLP-and-DOCP-manipulations","page":"NLP manipulations","title":"NLP and DOCP manipulations","text":"","category":"section"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"We describe here some more advanced operations related to the discretized optimal control problem. When calling solve(ocp) three steps are performed internally:","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"first, the OCP is discretized into a DOCP (a nonlinear optimization problem),\nthen, this DOCP is solved with a nonlinear programming (NLP) solver, which returns a solution of the discretized problem,\nfinally, a functional solution of the OCP is rebuilt from the solution of the discretized problem.","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"These steps can also be done separately, for instance if you want to use your own NLP solver. ","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"Let us load the packages.","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"using OptimalControl\nusing Plots","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"We define a test problem","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"ocp = @def begin\n\n    t ∈ [0, 1], time\n    x ∈ R², state\n    u ∈ R, control\n\n    x(0) == [ -1, 0 ]\n    x(1) == [ 0, 0 ]\n\n    ẋ(t) == [ x₂(t), u(t) ]\n\n    ∫( 0.5u(t)^2 ) → min\n\nend\nnothing # hide","category":"page"},{"location":"tutorial-nlp.html#Discretization-and-NLP-problem","page":"NLP manipulations","title":"Discretization and NLP problem","text":"","category":"section"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"We discretize the problem.","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"docp, nlp = direct_transcription(ocp)\nnothing # hide","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"The DOCP contains information related to the transcription, including a copy of the original OCP, and the NLP is the resulting discretized problem, in our case an ADNLPModel.","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"We can now use the solver of our choice to solve it.","category":"page"},{"location":"tutorial-nlp.html#Resolution-of-the-NLP-problem","page":"NLP manipulations","title":"Resolution of the NLP problem","text":"","category":"section"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"For a first example we use the ipopt solver from NLPModelsIpopt.jl package to solve the NLP problem.","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"using NLPModelsIpopt\n\nnlp_sol = ipopt(nlp; print_level=5, mu_strategy=\"adaptive\", tol=1e-8, sb=\"yes\")\nnothing # hide","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"Then we can rebuild and plot an optimal control problem solution (note that the multipliers are optional, but the OCP costate will not be retrieved if the multipliers are not provided).","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"sol = build_OCP_solution(docp; primal=nlp_sol.solution, dual=nlp_sol.multipliers)\nplot(sol)","category":"page"},{"location":"tutorial-nlp.html#Change-the-NLP-solver","page":"NLP manipulations","title":"Change the NLP solver","text":"","category":"section"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"Alternatively, we can use MadNLP.jl to solve anew the NLP problem:","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"using MadNLP\n\nnlp_sol = madnlp(nlp)","category":"page"},{"location":"tutorial-nlp.html#Initial-guess","page":"NLP manipulations","title":"Initial guess","text":"","category":"section"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"An initial guess, including warm start, can be passed to direct_transcription the same way as for solve.","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"docp, nlp = direct_transcription(ocp; init=sol)\nnothing # hide","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"It can also be changed after the transcription is done, with  set_initial_guess.","category":"page"},{"location":"tutorial-nlp.html","page":"NLP manipulations","title":"NLP manipulations","text":"set_initial_guess(docp, nlp, sol)\nnothing # hide","category":"page"},{"location":"tutorial-continuation.html#Discrete-continuation","page":"Discrete continuation","title":"Discrete continuation","text":"","category":"section"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"Using the warm start option, it is easy to implement a basic discrete continuation method, where a sequence of problems is solved using each solution as initial guess for the next problem. This usually gives better and faster convergence than solving each problem with the same initial guess, and is a way to handle problems that require a good initial guess.","category":"page"},{"location":"tutorial-continuation.html#Continuation-on-parametric-OCP","page":"Discrete continuation","title":"Continuation on parametric OCP","text":"","category":"section"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"The most compact syntax to perform a discrete continuation is to use a function that returns the OCP for a given value of the continuation parameter, and solve a sequence of these problems. We illustrate this on a very basic double integrator with increasing fixed final time.","category":"page"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"First we load the required packages:","category":"page"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"using OptimalControl\nusing NLPModelsIpopt\nusing Printf\nusing Plots","category":"page"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"and write a function that returns the OCP for a given final time:","category":"page"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"function ocp_T(T)\n    ocp = @def begin\n        t ∈ [0, T], time\n        x ∈ R², state\n        u ∈ R, control\n        q = x₁\n        v = x₂\n        q(0) == 0\n        v(0) == 0\n        q(T) == 1\n        v(T) == 0\n        ẋ(t) == [ v(t), u(t) ]\n        ∫(u(t)^2) → min\n    end\n    return ocp\nend\nnothing # hide","category":"page"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"Then we perform the continuation with a simple for loop, using each solution to initialize the next problem.","category":"page"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"init1 = ()\nfor T=1:5\n    ocp1 = ocp_T(T) \n    sol1 = solve(ocp1; display=false, init=init1)\n    global init1 = sol1\n    @printf(\"T %.2f objective %9.6f iterations %d\\n\", T, objective(sol1), iterations(sol1))\nend","category":"page"},{"location":"tutorial-continuation.html#Continuation-on-global-variable","page":"Discrete continuation","title":"Continuation on global variable","text":"","category":"section"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"As a second example, we show how to avoid redefining a new OCP each time, and modify the original one instead. More precisely we now solve a Goddard problem for a decreasing maximal thrust. If we store the value for Tmax in a global variable, we can simply modify this variable and keep the same OCP problem during the continuation.","category":"page"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"Let us first define the Goddard problem (note that the formulation below illustrates all the possible constraints types, and the problem could be defined in a more compact way).","category":"page"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"Cd = 310\nTmax = 3.5\nβ = 500\nb = 2\nfunction F0(x)\n    r, v, m = x\n    D = Cd * v^2 * exp(-β*(r - 1))\n    return [ v, -D/m - 1/r^2, 0 ]\nend\nfunction F1(x)\n    r, v, m = x\n    return [ 0, Tmax/m, -b*Tmax ]\nend\nr0 = 1\nv0 = 0\nm0 = 1\nmf = 0.6\nx0 = [r0, v0, m0]\nvmax = 0.1\n\n@def ocp begin\n    tf ∈ R, variable\n    t ∈ [0, tf], time\n    x ∈ R^3, state\n    u ∈ R, control\n    0.01 ≤ tf ≤ Inf\n    r = x[1]\n    v = x[2]\n    m = x[3]\n    x(0) == x0\n    m(tf) == mf\n    r0 ≤ r(t) ≤ r0 + 0.1\n    v0 ≤ v(t) ≤ vmax\n    mf ≤ m(t) ≤ m0\n    0 ≤ u(t) ≤ 1\n    ẋ(t) == F0(x(t)) + u(t) * F1(x(t))\n    r(tf) → max\nend\n\nsol0 = solve(ocp; display=false)\n@printf(\"Objective for reference solution %.6f\\n\", objective(sol0))","category":"page"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"Then we perform the continuation on the maximal thrust.","category":"page"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"sol       = sol0\nTmax_list = []\nobj_list  = []\nfor Tmax_local=3.5:-0.5:1\n    global Tmax = Tmax_local  \n    global sol = solve(ocp; display=false, init=sol)\n    @printf(\"Tmax %.2f objective %.6f iterations %d\\n\", Tmax, objective(sol), iterations(sol))\n    push!(Tmax_list, Tmax)\n    push!(obj_list, objective(sol))\nend ","category":"page"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"We plot now the objective w.r.t the maximal thrust, as well as both solutions for Tmax=3.5 and Tmax=1.","category":"page"},{"location":"tutorial-continuation.html","page":"Discrete continuation","title":"Discrete continuation","text":"using Plots.PlotMeasures # for leftmargin\n\nplt_obj = plot(Tmax_list, obj_list;\n    seriestype=:scatter,\n    title=\"Goddard problem\",\n    label=\"r(tf)\", \n    xlabel=\"Maximal thrust (Tmax)\",\n    ylabel=\"Maximal altitude r(tf)\")\n\nplt_sol = plot(sol0; label=\"(Tmax = \"*string(Tmax_list[1])*\")\")\nplot!(plt_sol, sol;  label=\"(Tmax = \"*string(Tmax_list[end])*\")\")\n\nlayout = grid(2, 1, heights=[0.2, 0.8])\nplot(plt_obj, plt_sol; layout=layout, size=(800, 1000), leftmargin=5mm)","category":"page"},{"location":"index.html#Tutorials","page":"Getting Started","title":"Tutorials","text":"","category":"section"},{"location":"index.html","page":"Getting Started","title":"Getting Started","text":"This collection of tutorials is part of the control-toolbox ecosystem. The control-toolbox ecosystem gathers Julia packages for mathematical control and applications. It aims to provide tools to model and solve optimal control problems with ordinary differential equations by direct and indirect methods. If you want to define an optimal control problem and solve it, please check the documentation.","category":"page"},{"location":"index.html","page":"Getting Started","title":"Getting Started","text":"From this page, you can find a list of tutorials to solve optimal control problems with OptimalControl.","category":"page"},{"location":"index.html#Reproducibility","page":"Getting Started","title":"Reproducibility","text":"","category":"section"},{"location":"index.html","page":"Getting Started","title":"Getting Started","text":"<details><summary>The documentation of this package was built using these direct dependencies,</summary>","category":"page"},{"location":"index.html","page":"Getting Started","title":"Getting Started","text":"using Pkg # hide\nPkg.status() # hide","category":"page"},{"location":"index.html","page":"Getting Started","title":"Getting Started","text":"</details>","category":"page"},{"location":"index.html","page":"Getting Started","title":"Getting Started","text":"<details><summary>and using this machine and Julia version.</summary>","category":"page"},{"location":"index.html","page":"Getting Started","title":"Getting Started","text":"using InteractiveUtils # hide\nversioninfo() # hide","category":"page"},{"location":"index.html","page":"Getting Started","title":"Getting Started","text":"</details>","category":"page"},{"location":"index.html","page":"Getting Started","title":"Getting Started","text":"<details><summary>A more complete overview of all dependencies and their versions is also provided.</summary>","category":"page"},{"location":"index.html","page":"Getting Started","title":"Getting Started","text":"using Pkg # hide\nPkg.status(; mode = PKGMODE_MANIFEST) # hide","category":"page"},{"location":"index.html","page":"Getting Started","title":"Getting Started","text":"</details>","category":"page"},{"location":"index.html","page":"Getting Started","title":"Getting Started","text":"using TOML\nusing Markdown\nversion = TOML.parse(read(\"../../Project.toml\", String))[\"version\"]\nname = TOML.parse(read(\"../../Project.toml\", String))[\"name\"]\nlink_manifest = \"https://github.com/SciML/\" *\n                name *\n                \".jl/tree/gh-pages/v\" *\n                version *\n                \"/assets/Manifest.toml\"\nlink_project = \"https://github.com/SciML/\" *\n               name *\n               \".jl/tree/gh-pages/v\" *\n               version *\n               \"/assets/Project.toml\"\nMarkdown.parse(\"\"\"You can also download the\n[manifest]($link_manifest)\nfile and the\n[project]($link_project)\nfile.\n\"\"\")","category":"page"},{"location":"tutorial-goddard.html#Direct-and-indirect-methods-for-the-Goddard-problem","page":"Goddard: direct, indirect","title":"Direct and indirect methods for the Goddard problem","text":"","category":"section"},{"location":"tutorial-goddard.html#Introduction","page":"Goddard: direct, indirect","title":"Introduction","text":"","category":"section"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"<img src=\"./assets/Goddard_and_Rocket.jpg\" style=\"float: left; margin: auto 10px;\" width=\"200px\">","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"For this example, we consider the well-known Goddard problem[1] [2] which models the ascent of a rocket through the atmosphere, and we restrict here ourselves to vertical (one dimensional) trajectories. The state variables are the altitude r, speed v and mass m of the rocket during the flight, for a total dimension of 3. The rocket is subject to gravity g, thrust u and drag force D (function of speed and altitude). The final time t_f is free, and the objective is to reach a maximal altitude with a bounded fuel consumption.","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"We thus want to solve the optimal control problem in Mayer form","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"    r(t_f) to max","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"subject to the controlled dynamics","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"    dotr = v quad\n    dotv = fracT_maxu - D(rv)m - g quad\n    dotm = -u","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"and subject to the control constraint u(t) in 01 and the state constraint v(t) leq v_max. The initial state is fixed while only the final mass is prescribed.","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"note: Nota bene\nThe Hamiltonian is affine with respect to the control, so singular arcs may occur, as well as constrained arcs due to the path constraint on the velocity (see below).","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"We import the OptimalControl.jl package to define the optimal control problem and NLPModelsIpopt.jl to solve it.  We import the Plots.jl package to plot the solution.  The OrdinaryDiffEq.jl package is used to  define the shooting function for the indirect method and the MINPACK.jl package permits to solve the shooting equation.","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"using OptimalControl  # to define the optimal control problem and more\nusing NLPModelsIpopt  # to solve the problem via a direct method\nusing OrdinaryDiffEq  # to get the Flow function from OptimalControl\nusing MINPACK         # NLE solver: use to solve the shooting equation\nusing Plots           # to plot the solution","category":"page"},{"location":"tutorial-goddard.html#Optimal-control-problem","page":"Goddard: direct, indirect","title":"Optimal control problem","text":"","category":"section"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"We define the problem","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"const t0 = 0      # initial time\nconst r0 = 1      # initial altitude\nconst v0 = 0      # initial speed\nconst m0 = 1      # initial mass\nconst vmax = 0.1  # maximal authorized speed\nconst mf = 0.6    # final mass to target\n\nocp = @def begin # definition of the optimal control problem\n\n    tf ∈ R, variable\n    t ∈ [t0, tf], time\n    x = (r, v, m) ∈ R³, state\n    u ∈ R, control\n\n    x(t0) == [r0, v0, m0]\n    m(tf) == mf,         (1)\n    0 ≤ u(t) ≤ 1\n    r(t) ≥ r0\n    0 ≤ v(t) ≤ vmax\n\n    ẋ(t) == F0(x(t)) + u(t) * F1(x(t))\n\n    r(tf) → max\n\nend\n\n# Dynamics\nconst Cd = 310\nconst Tmax = 3.5\nconst β = 500\nconst b = 2\n\nF0(x) = begin\n    r, v, m = x\n    D = Cd * v^2 * exp(-β*(r - 1)) # Drag force\n    return [v, -D/m - 1/r^2, 0]\nend\n\nF1(x) = begin\n    r, v, m = x\n    return [0, Tmax/m, -b*Tmax]\nend\nnothing # hide","category":"page"},{"location":"tutorial-goddard.html#Direct-method","page":"Goddard: direct, indirect","title":"Direct method","text":"","category":"section"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"We then solve it","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"direct_sol = solve(ocp; grid_size=100)\nnothing # hide","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"and plot the solution","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"plt = plot(direct_sol, label=\"direct\", size=(800, 800))","category":"page"},{"location":"tutorial-goddard.html#tutorial-goddard-structure","page":"Goddard: direct, indirect","title":"Structure of the solution","text":"","category":"section"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"We first determine visually the structure of the optimal solution which is composed of a bang arc with maximal control, followed by a singular arc, then by a boundary arc and the final arc is with zero control. Note that the switching function vanishes along the singular and boundary arcs.","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"t = time_grid(direct_sol)   # the time grid as a vector\nx = state(direct_sol)       # the state as a function of time\nu = control(direct_sol)     # the control as a function of time\np = costate(direct_sol)     # the costate as a function of time\n\nH1 = Lift(F1)           # H1(x, p) = p' * F1(x)\nφ(t) = H1(x(t), p(t))   # switching function\ng(x) = vmax - x[2]      # state constraint v ≤ vmax\n\nu_plot  = plot(t, u,     label = \"u(t)\")\nH1_plot = plot(t, φ,     label = \"H₁(x(t), p(t))\")\ng_plot  = plot(t, g ∘ x, label = \"g(x(t))\")\n\nplot(u_plot, H1_plot, g_plot, layout=(3,1), size=(500, 500))","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"We are now in position to solve the problem by an indirect shooting method. We first define the four control laws in feedback form and their associated flows. For this we need to compute some Lie derivatives, namely Poisson brackets of Hamiltonians (themselves obtained as lifts to the cotangent bundle of vector fields), or derivatives of functions along a vector field. For instance, the control along the minimal order singular arcs is obtained as the quotient","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"u_s = -fracH_001H_101","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"of length three Poisson brackets:","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"H_001 = H_0H_0H_1 quad H_101 = H_1H_0H_1","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"where, for two Hamiltonians H and G,","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"HG = (nabla_p Hnabla_x G) - (nabla_x Hnabla_p G)","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"While the Lie derivative of a function f wrt. a vector field X is simply obtained as","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"(X cdot f)(x) = f(x) cdot X(x)","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"and is used to the compute the control along the boundary arc,","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"u_b(x) = -(F_0 cdot g)(x)  (F_1 cdot g)(x)","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"as well as the associated multiplier for the order one state constraint on the velocity:","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"mu(x p) = H_01(x p)  (F_1 cdot g)(x)","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"note: Poisson bracket and Lie derivative\nThe Poisson bracket HG is also given by the Lie derivative of G along the Hamiltonian vector field X_H = (nabla_p H -nabla_x H) of H, that is    HG = X_H cdot Gwhich is the reason why we use the @Lie macro to compute Poisson brackets below.","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"With the help of differential geometry primitives, these expressions are straightforwardly translated into Julia code:","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"# Controls\nconst u0 = 0                            # off control\nconst u1 = 1                            # bang control\n\nH0 = Lift(F0)                           # H0(x, p) = p' * F0(x)\nH01  = @Lie {H0, H1}\nH001 = @Lie {H0, H01}\nH101 = @Lie {H1, H01}\nus(x, p) = -H001(x, p) / H101(x, p)     # singular control\n\nub(x) = -(F0⋅g)(x) / (F1⋅g)(x)          # boundary control\nμ(x, p) = H01(x, p) / (F1⋅g)(x)         # multiplier associated to the state constraint g\n\n# Flows\nf0 = Flow(ocp, (x, p, tf) -> u0)\nf1 = Flow(ocp, (x, p, tf) -> u1)\nfs = Flow(ocp, (x, p, tf) -> us(x, p))\nfb = Flow(ocp, (x, p, tf) -> ub(x), (x, u, tf) -> g(x), (x, p, tf) -> μ(x, p))\nnothing # hide","category":"page"},{"location":"tutorial-goddard.html#Shooting-function","page":"Goddard: direct, indirect","title":"Shooting function","text":"","category":"section"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"Then, we define the shooting function according to the optimal structure we have determined, that is a concatenation of four arcs.","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"x0 = [r0, v0, m0] # initial state\n\nfunction shoot!(s, p0, t1, t2, t3, tf)\n\n    x1, p1 = f1(t0, x0, p0, t1)\n    x2, p2 = fs(t1, x1, p1, t2)\n    x3, p3 = fb(t2, x2, p2, t3)\n    xf, pf = f0(t3, x3, p3, tf)\n\n    s[1] = xf[3] - mf                             # final mass constraint\n    s[2:3] = pf[1:2] - [1, 0]                     # transversality conditions\n    s[4] = H1(x1, p1)                             # H1 = H01 = 0\n    s[5] = H01(x1, p1)                            # at the entrance of the singular arc\n    s[6] = g(x2)                                  # g = 0 when entering the boundary arc\n    s[7] = H0(xf, pf)                             # since tf is free\n\nend\nnothing # hide","category":"page"},{"location":"tutorial-goddard.html#Initial-guess","page":"Goddard: direct, indirect","title":"Initial guess","text":"","category":"section"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"To solve the problem by an indirect shooting method, we then need a good initial guess, that is a good approximation of the initial costate, the three switching times and the final time.","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"η = 1e-3\nt13 = t[ abs.(φ.(t)) .≤ η ]\nt23 = t[ 0 .≤ (g ∘ x).(t) .≤ η ]\np0 = p(t0)\nt1 = min(t13...)\nt2 = min(t23...)\nt3 = max(t23...)\ntf = t[end]\n\nprintln(\"p0 = \", p0)\nprintln(\"t1 = \", t1)\nprintln(\"t2 = \", t2)\nprintln(\"t3 = \", t3)\nprintln(\"tf = \", tf)\n\n# Norm of the shooting function at solution\nusing LinearAlgebra: norm\ns = similar(p0, 7)\nshoot!(s, p0, t1, t2, t3, tf)\nprintln(\"\\nNorm of the shooting function: ‖s‖ = \", norm(s), \"\\n\")","category":"page"},{"location":"tutorial-goddard.html#Indirect-shooting","page":"Goddard: direct, indirect","title":"Indirect shooting","text":"","category":"section"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"We aggregate the data to define the initial guess vector.","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"ξ = [p0..., t1, t2, t3, tf] # initial guess","category":"page"},{"location":"tutorial-goddard.html#MINPACK.jl","page":"Goddard: direct, indirect","title":"MINPACK.jl","text":"","category":"section"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"We can use NonlinearSolve.jl package or, instead, the  MINPACK.jl package to solve  the shooting equation. To compute the Jacobian of the shooting function we use the  DifferentiationInterface.jl package with  ForwardDiff.jl backend.","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"using DifferentiationInterface\nimport ForwardDiff\nbackend = AutoForwardDiff()\nnothing # hide","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"Let us define the problem to solve.","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"# auxiliary function with aggregated inputs\nnle!  = ( s, ξ) -> shoot!(s, ξ[1:3], ξ[4], ξ[5], ξ[6], ξ[7])\n\n# Jacobian of the (auxiliary) shooting function\njnle! = (js, ξ) -> jacobian!(nle!, similar(ξ), js, backend, ξ)\nnothing # hide","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"We are now in position to solve the problem with the hybrj solver from MINPACK.jl through the fsolve  function, providing the Jacobian. Let us solve the problem and retrieve the initial costate solution.","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"# resolution of S(ξ) = 0\nindirect_sol = fsolve(nle!, jnle!, ξ, show_trace=true)\n\n# we retrieve the costate solution together with the times\np0 = indirect_sol.x[1:3]\nt1 = indirect_sol.x[4]\nt2 = indirect_sol.x[5]\nt3 = indirect_sol.x[6]\ntf = indirect_sol.x[7]\n\nprintln(\"\")\nprintln(\"p0 = \", p0)\nprintln(\"t1 = \", t1)\nprintln(\"t2 = \", t2)\nprintln(\"t3 = \", t3)\nprintln(\"tf = \", tf)\n\n# Norm of the shooting function at solution\ns = similar(p0, 7)\nshoot!(s, p0, t1, t2, t3, tf)\nprintln(\"\\nNorm of the shooting function: ‖s‖ = \", norm(s), \"\\n\")","category":"page"},{"location":"tutorial-goddard.html#tutorial-goddard-plot","page":"Goddard: direct, indirect","title":"Plot of the solution","text":"","category":"section"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"We plot the solution of the indirect solution (in red) over the solution of the direct method  (in blue).","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"f = f1 * (t1, fs) * (t2, fb) * (t3, f0) # concatenation of the flows\nflow_sol = f((t0, tf), x0, p0)          # compute the solution: state, costate, control...\n\nplot!(plt, flow_sol, label=\"indirect\")","category":"page"},{"location":"tutorial-goddard.html#References","page":"Goddard: direct, indirect","title":"References","text":"","category":"section"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"[1]: R.H. Goddard. A Method of Reaching Extreme Altitudes, volume 71(2) of Smithsonian Miscellaneous Collections. Smithsonian institution, City of Washington, 1919.","category":"page"},{"location":"tutorial-goddard.html","page":"Goddard: direct, indirect","title":"Goddard: direct, indirect","text":"[2]: H. Seywald and E.M. Cliff. Goddard problem in presence of a dynamic pressure limit. Journal of Guidance, Control, and Dynamics, 16(4):776–781, 1993.","category":"page"}]
}
